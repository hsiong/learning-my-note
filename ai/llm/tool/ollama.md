# åˆå§‹åŒ–

## å®‰è£… **Ollama**

```
curl -fsSL https://ollama.com/install.sh | sh
```

## é…ç½®å›½å†…æº

1. æ”¯æŒçš„â€œå›½å†…é•œåƒæºâ€ç¤ºä¾‹

https://blog.csdn.net/Water_Jack/article/details/147600755 

åˆ—çš„æ˜¯å‡ å®¶å¯ç”¨çš„é•œåƒ / ä¸­è½¬æºï¼š

- é˜¿é‡Œäº‘ï¼š`https://registry.ollama.ai`ï¼ˆçœ‹èµ·æ¥æ˜¯èµ°äº†å›½å†…åŠ é€Ÿçº¿è·¯çš„åŒåŸŸåï¼‰
- DeepSeek å®˜æ–¹é•œåƒï¼š`https://ollama.deepseek.com`
- æµ™æ±Ÿå¤§å­¦é•œåƒç«™ï¼š`https://ollama.zju.edu.cn`
- é­”æ­ç¤¾åŒºï¼š`https://ollama.modelscope.cn`

------

2. Linux / macOS é…ç½® `config.json`

```
mkdir -p ~/.ollama

cat << 'EOF' > ~/.ollama/config.json
{
  "registry": {
    "mirrors": {
      "registry.ollama.ai": "https://ollama.modelscope.cn"
    }
  }
}
EOF
```

å¦‚æœä½ æƒ³ç”¨åˆ«çš„é•œåƒï¼Œæ›¿æ¢æˆä¾‹å¦‚ï¼š

```
{
  "registry": {
    "mirrors": {
      "registry.ollama.ai": "https://ollama.deepseek.com"
    }
  }
}
```

ç„¶åé‡å¯ Ollama æœåŠ¡è®©é…ç½®ç”Ÿæ•ˆï¼š

```
sudo systemctl restart ollama
```

## é…ç½®æƒé‡æ–‡ä»¶è·¯å¾„

```
sudo EDITOR=vim systemctl edit ollama
```

ä¿®æ”¹ç›®å½•

```
[Unit]
Description=Ollama Service
After=network-online.target

[Service]
ExecStart=/usr/local/bin/ollama serve
Restart=always
User=root
Group=root

# â† ä½ ç°åœ¨å·²æœ‰çš„ PATH é…ç½®
Environment="PATH=/home/hsiong/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin"

# â† åœ¨è¿™é‡Œæ–°å¢ OLLAMA_MODELSï¼ˆè¿™ä¸€è¡Œå°±æ˜¯ä½ è¦åŠ çš„ï¼‰
Environment="OLLAMA_MODELS=/mnt/bigdisk/ollama-models"

[Install]
WantedBy=multi-user.target
```

+ æ³¨æ„: åŒæ—¶ä¿®æ”¹ User å’Œ Group â­ï¸â­ï¸â­ï¸
+ ä½ å¯ä»¥è¿™æ ·ç¡®è®¤ä¸€ä¸‹ï¼š

```
sudo systemctl daemon-reload
sudo systemctl restart ollama
systemctl show ollama | grep OLLAMA_MODELS

```

## åŸºæœ¬æ“ä½œ

### å¯åŠ¨

```
ollama serve
```

å¯åŠ¨ **Ollama æœåŠ¡ç«¯**ï¼Œæä¾› `http://localhost:11434` APIã€‚

> è°ƒç”¨
>
> curl http://localhost:11434/api/generate \
>   -H "Content-Type: application/json" \
>   -d '{
>     "model": "qwen2.5:7b-instruct-q4_0",
>     "prompt": "å†™ä¸€æ®µ 50 å­—å·¦å³çš„ä¸­æ–‡è‡ªæˆ‘ä»‹ç»ï¼š",
>     "stream": false
>   }'
>
> åœ¨ Ollama é‡Œï¼š
>
> - **`æ¨¡å‹å` å¯ä»¥å¸¦ tagï¼Œä¹Ÿå¯ä»¥ä¸å¸¦ tag**
>    ä¾‹å­ï¼ˆå®˜æ–¹æ–‡æ¡£é‡Œçš„ CodeLlamaï¼‰ï¼š
>   - æœ‰ tagï¼š`codellama:latest`
>   - ç›´æ¥ç”¨ï¼š`"model": "codellama"` ä¸€æ ·èƒ½ç”¨é»˜è®¤ç‰ˆæœ¬ï¼ˆå®é™…å°±æ˜¯ latestï¼‰

### æ‹‰å–

```
ollama pull xxx
```

ä½  `ollama pull xxx` ä¸‹æ¥çš„æ‰€æœ‰æ¨¡å‹ï¼Œä¸»è¦æ˜¯å  **ç¡¬ç›˜ç©ºé—´**ã€‚

å°±ç®—ä½ æ‹‰äº† 10 ä¸ª 7B / 14B æ¨¡å‹ï¼Œåªè¦ä¸åŒæ—¶åŠ è½½ï¼Œå®ƒä»¬åªå ç¡¬ç›˜ï¼Œä¸åƒæ˜¾å­˜ã€‚

> ollama æ”¯æŒæ–­ç‚¹ç»­ä¼ 

### è¿è¡Œ

```
ollama run qwen2.5:7b-instruct-q4_0 "ä½ å¥½"
```

åªæœ‰å½“ä½  **å®é™…è¿è¡Œ** æŸä¸ªæ¨¡å‹ï¼ˆ`ollama run` æˆ– API è¯·æ±‚ï¼‰æ—¶ï¼Œè¿™ä¸ªæ¨¡å‹æ‰ä¼šè¢«åŠ è½½åˆ°å†…å­˜/æ˜¾å­˜é‡Œã€‚

è¿è¡Œå®Œä¸€æ®µæ—¶é—´ä¸å†ç”¨ï¼ŒOllama ä¼šåœ¨ä¸€æ®µç©ºé—²æ—¶é—´åè‡ªåŠ¨æŠŠå®ƒå¸è½½ï¼ˆé»˜è®¤å¤§çº¦å‡ åˆ†é’Ÿï¼Œå¯é€šè¿‡ `OLLAMA_KEEP_ALIVE` æˆ– `keep_alive` å‚æ•°è°ƒæ•´ï¼‰ã€‚

Ollama çš„è¡Œä¸ºæ˜¯ï¼š

- **é¦–æ¬¡è°ƒç”¨è¯¥æ¨¡å‹ï¼ˆrun / API è°ƒç”¨ï¼‰æ—¶åŠ è½½è¿›å†…å­˜/æ˜¾å­˜**
- åŠ è½½å®Œæˆåï¼š
  - æ¨¡å‹ **å¸¸é©»ï¼ˆcachedï¼‰** ä¸€æ®µæ—¶é—´
  - ä¸ä¼šæ¯æ¬¡ API è°ƒç”¨éƒ½é‡æ–°åŠ è½½
  - åç»­è°ƒç”¨åŸºæœ¬æ˜¯ **å³æ—¶å“åº”**

ä¹Ÿå°±æ˜¯è¯´ï¼Œä½ åªè¦ **ç¬¬ä¸€æ¬¡è§¦å‘ä¸€æ¬¡ run æˆ– API è°ƒç”¨ï¼Œå°±ç­‰äºè®©å®ƒâ€œé¢„çƒ­â€äº†**ã€‚

### å…³é—­

1. æ˜¾å¼æŠŠè¿™ä¸ªæ¨¡å‹ä»å†…å­˜é‡Œâ€œå…³æ‰â€ï¼š

```
ollama stop qwen2.5:7b-instruct-q4_0
```

### åˆ é™¤



### å¸¸é©»

```
ollama run qwen2.5:7b-instruct-q4_0 --keepalive -1
```

å«ä¹‰ï¼š

- `--keepalive -1`ï¼šå‘Šè¯‰ Ollama **è¿™æ¬¡åŠ è½½çš„æ¨¡å‹æ— é™æœŸå¸¸é©»**ï¼Œç›´åˆ°ä½ æ‰‹åŠ¨å…³æ‰è¿›ç¨‹ / é‡å¯æœåŠ¡ã€‚
- ä¸åŠ å‚æ•°æ—¶ï¼Œé»˜è®¤æ˜¯â€œç©ºé—²å‡ åˆ†é’Ÿåè‡ªåŠ¨å¸è½½â€ã€‚
- ä¸å»ºè®®ä½¿ç”¨

### æ¨¡å‹çœŸå®å¯ç”¨ä¸Šä¸‹æ–‡

è¿è¡Œï¼š

```
ollama show qwen3:32b-q4_K_M
```

è¾“å‡ºé‡Œæ˜¯å¦æœ‰ï¼š

```
parameter ctx_len: 4096
```

# ç›‘æ§

## æ—¥å¿—

Ollama é»˜è®¤æŠŠæ—¥å¿—å†™åˆ°ï¼š

### **ğŸ“ Linux / Ubuntu**

```
/usr/share/ollama/.ollama/logs/ollama.log
```

å¦‚æœä½ ç”¨ systemdï¼ˆå¤§éƒ¨åˆ†æœåŠ¡å™¨éƒ½æ˜¯ï¼‰ï¼Œå…¶å®ä¹Ÿå¯ä»¥ç”¨ï¼š

```
journalctl -u ollama -f
```

`-f` = è·Ÿè¸ªæ—¥å¿—ï¼ˆå®æ—¶åˆ·æ–°ï¼‰

## **å®æ—¶ç›‘æ§ç³»ç»Ÿèµ„æºï¼ˆGPU/CPU/å†…å­˜ï¼‰**

ä½¿ç”¨ä»¥ä¸‹å·¥å…·ï¼š

------

### ğŸ”¥ **(1) GPU å®æ—¶ç›‘æ§**

```
watch -n 1 nvidia-smi
```

å¯çœ‹åˆ°ï¼š

- GPU åˆ©ç”¨ç‡
- æ˜¾å­˜å ç”¨
- GPU æ¸©åº¦
- æ˜¾å­˜æ³„æ¼æƒ…å†µï¼ˆéå¸¸å…³é”®ï¼‰

### æƒ³çœ‹æ¯ä¸ªè¿›ç¨‹çš„æ˜¾å­˜å ç”¨ï¼ˆæœ€å¸¸ç”¨ï¼‰

```
nvidia-smi pmon -s um
```

------

### ğŸ”¥ **(2) CPU & å†…å­˜ç›‘æ§**

```
htop
```

æˆ–

```
top
```

------

### ğŸ”¥ (3) ç»“åˆ GPU + CPU + å†…å­˜ç›‘æ§ï¼ˆæ¨èï¼‰

**nvtop**ï¼ˆå¤š GPU å¯è§†åŒ–ï¼‰

å®‰è£…ï¼š

```
sudo apt install nvtop
```

è¿è¡Œï¼š

```
nvtop
```

------

## ğŸŸ¦ 5. **ç›‘æ§ Ollama Qwen æ¨¡å‹çš„ QPS / è¯·æ±‚ä¿¡æ¯ï¼ˆAPI å±‚ï¼‰**

å¦‚æœä½ æ˜¯ç”¨ API è°ƒç”¨ï¼š

### æŸ¥çœ‹ access logï¼ˆè¯·æ±‚æ—¥å¿—ï¼‰

ä½ç½®é€šå¸¸åœ¨ï¼š

```
/usr/share/ollama/.ollama/logs/access.log
```

å¯ä»¥å®æ—¶æŸ¥çœ‹ï¼š

```
tail -f /usr/share/ollama/.ollama/logs/access.log
```

èƒ½çœ‹åˆ°ï¼š

- è¯·æ±‚æ—¶é—´
- endpoint
- Model nameï¼ˆä¾‹å¦‚ï¼šqwen2.5-14b-q4ï¼‰
- è€—æ—¶
- token æ•°
- å®¢æˆ·ç«¯ IP

------

## ğŸŸ© 6. **å¼€å¯ Ollama è°ƒè¯•æ¨¡å¼ï¼ˆé«˜çº§ï¼‰**

å¯ä»¥è®© Ollama è¾“å‡ºæ›´è¯¦ç»†æ—¥å¿—ã€‚

ä¸´æ—¶å¼€å¯ï¼š

```
OLLAMA_DEBUG=1 ollama serve
```

æˆ–ä¿®æ”¹ serviceï¼š

```
sudo systemctl edit ollama
```

åŠ å…¥ï¼š

```
[Service]
Environment="OLLAMA_DEBUG=1"
```

é‡å¯ï¼š

```
sudo systemctl restart ollama
```

------

## ğŸŸ§ 7. **å¦‚æœä½ å¸Œæœ›æ›´ä¸“ä¸šç›‘æ§ï¼ˆæ¨èï¼‰**

å¯ä»¥åŠ ä¸Š Prometheus + Grafanaï¼š

### å¯¼å‡º Ollama ç»Ÿè®¡ä¿¡æ¯

ç›®å‰éœ€è¦å€ŸåŠ©ç¤¾åŒº exporterï¼Œä¾‹å¦‚ï¼š

```
https://github.com/ollama/ollama-prometheus-exporter
```

æ”¯æŒç›‘æ§ï¼š

- æ¯ç§’è¯·æ±‚æ•°ï¼ˆQPSï¼‰
- token/s æ¨ç†é€Ÿåº¦
- æ¨¡å‹åŠ è½½æ—¶é—´
- ä¸€ä¸ªæ¨¡å‹å å¤šå°‘ GPU å†…å­˜
- æ¯ä¸ªè¯·æ±‚çš„å»¶è¿Ÿç»Ÿè®¡
- Errors ç»Ÿè®¡

Grafana å¯ä»¥ç›´æ¥å±•ç¤ºå¯è§†åŒ–å›¾è¡¨ã€‚

------

## ğŸŸ¦ 8. **æœ€ä½³ç›‘æ§ç»„åˆï¼ˆæˆ‘æ¨èï¼‰**

| ç›‘æ§å†…å®¹               | å·¥å…·                     |
| ---------------------- | ------------------------ |
| GPU ä½¿ç”¨ç‡ / æ˜¾å­˜å ç”¨  | nvidia-smi / nvtop       |
| CPU / å†…å­˜å ç”¨         | htop                     |
| Ollama æ—¥å¿—            | journalctl æˆ– ollama.log |
| API è°ƒç”¨æ—¥å¿—           | access.log               |
| é«˜çº§ç›‘æ§               | Prometheus + Grafana     |
| å®æ—¶æ¨¡å‹çŠ¶æ€ä¸è½½å…¥æƒ…å†µ | OLLAMA_DEBUG=1           |

# éƒ¨ç½² Embadding

## æ¨¡å‹é€‰å‹

ä»¥ä¸‹æ˜¯å‡ æ¬¾åœ¨ä¸­æ–‡è¯­ä¹‰ä»»åŠ¡ä¸Šè¡¨ç°ä¸é”™çš„æ¨¡å‹ï¼š

| æ¨¡å‹åç§°                                                   | æ¦‚è¦                                                         | ç‰¹ç‚¹ & é€‚ç”¨åœºæ™¯                                              |
| ---------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| BGEâ€‘M3                                                     | ä¸­å›½å›¢é˜Ÿå¼€æºçš„å¤šè¯­è¨€åµŒå…¥æ¨¡å‹ï¼Œä¸“æ³¨äºä¸­æ–‡è¡¨ç°ã€‚[53AI+2arXiv+2](https://www.53ai.com/news/RAG/2025031609253.html?utm_source=chatgpt.com) | å‘é‡ç»´åº¦ 1024ï¼Œæ”¯æŒæœ€å¤§åºåˆ—é•¿åº¦è¾ƒé•¿ï¼ˆ8192 tokensï¼‰[53AI+1](https://www.53ai.com/news/RAG/2025031609253.html?utm_source=chatgpt.com) ã€‚é€‚åˆä¸­æ–‡æ£€ç´¢ã€è·¨è¯­è¨€åº”ç”¨ã€‚ |
| Qwen3â€‘Embedding ç³»åˆ—                                       | Alibaba æä¾›çš„ â€œQwen3 Embeddingâ€ æ¨¡å‹ç³»åˆ—ï¼Œä»¥å¤šè¯­è¨€å’Œå¤§è§„æ¨¡é‡åŒ–è‘—ç§°ã€‚[Hugging Face+1](https://huggingface.co/Qwen/Qwen3-Embedding-8B?utm_source=chatgpt.com) | ä¸ä»…ä¸­æ–‡ï¼Œä¹Ÿæ”¯æŒå¤šè¯­è¨€ã€‚å¯é€‰æ¨¡å‹è§„æ¨¡æœ‰ 0.6B / 4B / 8B ç­‰å‚æ•°é‡ã€‚é€‚åˆéœ€è¦å¼ºè¯­ä¹‰ã€é•¿æ–‡æœ¬æˆ–è·¨è¯­è¨€åœºæ™¯ã€‚ |
| Seed1.5â€‘Embedding                                          | ByteDance å‡ºå“çš„ embedding æ¨¡å‹ï¼Œåœ¨ä¸­è‹±æ–‡ä»»åŠ¡ä¸Šéƒ½æœ‰ SOTA è¡¨ç°ã€‚[ByteDance Seed](https://seed.bytedance.com/en/blog/bytedance-s-seed1-5-embedding-model-achieves-sota-in-retrieval-training-details-unveiled?utm_source=chatgpt.com) | å¦‚æœä½ éœ€è¦æœ€æ–°ã€æ•ˆæœè¾ƒå¥½çš„æ¨¡å‹ï¼Œè¿™ä¸ªå€¼å¾—è€ƒè™‘ã€‚               |
| textâ€‘embeddingâ€‘3â€‘largeï¼ˆè‹±æ–‡æ¨¡å‹ï¼Œä½†åœ¨ä¸­æ–‡åœºæ™¯ä¹Ÿæœ‰è¢«ä½¿ç”¨ï¼‰ | æ¥è‡ª OpenAI çš„ embedding ç³»åˆ—ã€‚è™½ä¸»è¦ä¸ºè‹±æ–‡ï¼Œä½†æœ‰ä¸å°‘ä¸­æ–‡ä½¿ç”¨æ¡ˆä¾‹ã€‚[é£˜é€çš„é£+1](https://gameapp.club/post/2025-04-02-embedding-compare/?utm_source=chatgpt.com) | å¦‚æœä½ çš„åœºæ™¯ä¸ºä¸­è‹±æ··åˆæˆ–åè‹±æ–‡å†…å®¹ï¼Œè¿™æ¬¾ä¹Ÿå¯ä»¥ä½œä¸ºå¤‡é€‰ã€‚     |

>  ğŸ›  é€‰å‹æ—¶æ¨èè€ƒè™‘çš„ç»´åº¦
>
> åœ¨é€‰ embedding æ¨¡å‹æ—¶ï¼Œå»ºè®®ä»ä¸‹é¢è¿™äº›ç»´åº¦æ¥è¯„ä¼°ï¼š
>
> 1. **è¯­ä¹‰æ•ˆæœï¼ˆQualityï¼‰**
>    - æ¨¡å‹æ˜¯å¦èƒ½è¾ƒå¥½åœ°æ•æ‰ä¸­æ–‡è¯­ä¹‰ã€åŒºåˆ†ç»†å¾®å·®åˆ«ã€‚
>    - çœ‹ benchmark è¡¨ç°ï¼Œä¾‹å¦‚ä¸­æ–‡ä¸“é—¨çš„ C-MTEB æ•°æ®é›†ä¸­æˆç»©å¦‚ä½•ã€‚[arXiv+1](https://arxiv.org/pdf/2309.07597?utm_source=chatgpt.com)
> 2. **æ”¯æŒæ–‡æœ¬é•¿åº¦ / å‘é‡ç»´åº¦ /å¤šè¯­è¨€æ”¯æŒ**
>    - å¦‚æœä½ çš„åœºæ™¯åŒ…å«é•¿æ–‡æœ¬ï¼ˆå¦‚é•¿æ–‡æ¡£ã€æŠ¥å‘Šã€åˆåŒï¼‰â€”â€”å°±éœ€è¦æ¨¡å‹æ”¯æŒè¾ƒé•¿åºåˆ—ï¼ˆå¦‚ 8k tokensï¼‰ã€‚
>    - å‘é‡ç»´åº¦è¶Šå¤§ï¼Œä¸€èˆ¬èƒ½è¡¨ç¤ºæ›´å¤šä¿¡æ¯ï¼Œä½†è®¡ç®—æˆæœ¬ä¹Ÿä¼šæ›´é«˜ã€‚æ¯”å¦‚ BGE-M3 å‘é‡ç»´åº¦ 1024ã€‚[53AI](https://www.53ai.com/news/RAG/2025031609253.html?utm_source=chatgpt.com)
>    - æ˜¯å¦ä»…ä¸­æ–‡ã€è¿˜æ˜¯æ”¯æŒå¤šè¯­è¨€/ä¸­è‹±æ··åˆï¼Œè¿™å–å†³äºä½ çš„éœ€æ±‚ã€‚
> 3. **éƒ¨ç½²åŠæˆæœ¬**
>    - æ˜¯å¼€æºæ¨¡å‹è¿˜æ˜¯é—­æº APIï¼Ÿå¼€æºæ¨¡å‹è‡ªéƒ¨ç½²å¯èƒ½æ›´çµæ´»ã€æˆæœ¬å¯æ§ï¼Œä½†ç»´æŠ¤ä¹Ÿæ›´å¤æ‚ã€‚
>    - æ¨¡å‹çš„å‚æ•°é‡ã€æ¨ç†é€Ÿåº¦ã€å†…å­˜ï¼GPU æ¶ˆè€—ç­‰ä¹Ÿè¦è€ƒè™‘ã€‚[BentoML+1](https://www.bentoml.com/blog/a-guide-to-open-source-embedding-models?utm_source=chatgpt.com)
> 4. **åœºæ™¯åŒ¹é…**
>    - æ˜¯åšçŸ­æ–‡æœ¬è¯­ä¹‰åŒ¹é…ï¼Ÿè¿˜æ˜¯åšæ–‡æ¡£æ£€ç´¢ã€èšåˆï¼Ÿè¿˜æ˜¯åšå¤šæ¨¡æ€ï¼ˆæ–‡æœ¬ï¼‹å›¾ç‰‡ï¼‰ï¼Ÿä¸åŒæ¨¡å‹é€‚ç”¨ä¸åŒåœºæ™¯ã€‚
>    - ä¾‹å¦‚ï¼Œå¦‚æœæ˜¯åšâ€œé—®ç­”ä¸­çš„è¯­ä¹‰æœç´¢â€ï¼Œä½ å¯èƒ½ä¼˜å…ˆå…³æ³¨å¬å›ç‡å’Œè¯­ä¹‰ç›¸å…³æ€§ã€‚
> 5. **æ˜¯å¦éœ€è¦æœ¬åœ°åŒ– or è‡ªå®šä¹‰å¾®è°ƒ**
>    - å¦‚æœä½ çš„è¯­æ–™éå¸¸å‚ç›´ï¼ˆå¦‚æ³•å¾‹ã€é‡‘èã€åŒ»è¯ä¸­æ–‡è¯­æ–™ï¼‰ï¼Œå¯èƒ½è¿˜éœ€è¦æ¨¡å‹èƒ½æ”¯æŒåœ¨è¯¥é¢†åŸŸå¾®è°ƒã€‚
>    - æ˜¯å¦éœ€è¦æœ¬åœ°åŒ–éƒ¨ç½²ä»¥ä¿è¯æ•°æ®éšç§ä¸åˆè§„ã€‚

#### ğŸ“˜ **å‘é‡ç»´åº¦ 384 / 768 / 1536 å…¨é¢å¯¹æ¯”è¡¨**

| é¡¹ç›®                     | **384 ç»´**                   | **768 ç»´**                          | **1536 ç»´**                                 |
| ------------------------ | ---------------------------- | ----------------------------------- | ------------------------------------------- |
| **è¡¨è¾¾èƒ½åŠ›**             | è¾ƒä½ï¼ˆç²—è¯­ä¹‰ï¼‰               | ä¸­é«˜ï¼ˆä¸»æµèƒ½åŠ›ï¼‰                    | æœ€å¼ºï¼ˆç»†ç²’åº¦è¯­ä¹‰ï¼‰                          |
| **é€‚ç”¨åœºæ™¯**             | ç®€å• FAQã€å°çŸ¥è¯†åº“ã€è½»é‡æœç´¢ | ä¼ä¸šçº§æœç´¢ã€RAGã€æ¨èç³»ç»Ÿã€æŠ€æœ¯æ–‡æ¡£ | é«˜ç²¾åº¦ RAGã€ç§‘ç ”/æ³•å¾‹æ–‡æ¡£ã€å¤æ‚è¯­ä¹‰ã€å¤šè¯­è¨€ |
| **æœç´¢ç²¾åº¦ï¼ˆRecallï¼‰**   | ä¸­                           | é«˜                                  | æœ€é«˜                                        |
| **é•¿æ–‡æœ¬ç†è§£èƒ½åŠ›**       | å¼±                           | ä¸­                                  | å¼º                                          |
| **å¤šè¯­è¨€èƒ½åŠ›**           | ä¸­                           | ä¸­ä¸Š                                | å¼º                                          |
| **å™ªå£°é²æ£’æ€§**           | ä¸­                           | é«˜                                  | é«˜                                          |
| **æŸ¥è¯¢é€Ÿåº¦**             | â˜…â˜…â˜…â˜…â˜… æœ€å¿«                   | â˜…â˜…â˜…â˜…â˜† å¿«                            | â˜…â˜…â˜†â˜†â˜† è¾ƒæ…¢                                  |
| **å­˜å‚¨æˆæœ¬**             | â˜…â˜…â˜…â˜…â˜… æœ€ä½                   | â˜…â˜…â˜…â˜…â˜† ä¸­ç­‰                          | â˜…â˜†â˜†â˜†â˜† æœ€é«˜                                  |
| **å•æ¡å‘é‡å¤§å°ï¼ˆFP32ï¼‰** | ~1.5 KB                      | ~3 KB                               | ~6 KB                                       |
| **1000 ä¸‡æ¡å ç”¨å®¹é‡**    | ~15 GB                       | ~30 GB                              | ~60 GB                                      |
| **æˆæœ¬/æ€§èƒ½å¹³è¡¡**        | æˆæœ¬ä¼˜å…ˆ                     | æœ€å‡è¡¡                              | ç²¾åº¦ä¼˜å…ˆ                                    |
| **æ˜¯å¦é€‚åˆå¤§è§„æ¨¡å‘é‡åº“** | éå¸¸é€‚åˆ                     | é€‚åˆ                                | éœ€è¾ƒé«˜æˆæœ¬                                  |
| **å…¸å‹ç”¨é€”**             | FAQ æ£€ç´¢ã€æ„å›¾åˆ†ç±»ã€å°ç³»ç»Ÿ   | ä¼ä¸šæœç´¢ã€ç”µå•†æ¨èã€æŠ€æœ¯èµ„æ–™åˆ†æ    | ä¸“ä¸šé¢†åŸŸä¿¡æ¯æ£€ç´¢ã€æ·±åº¦ RAGã€å¤æ‚è·¨è¯­ä¹‰ä»»åŠ¡  |
| **æ¨èç†ç”±**             | æ€§ä»·æ¯”æœ€é«˜ã€é€Ÿåº¦å¿«           | ç»¼åˆè¡¨ç°æœ€ä½³                        | ç²¾åº¦æœ€å¼ºã€é€‚åˆä¸¥è‹›ä»»åŠ¡                      |

## æ–‡æœ¬å¤„ç†

### ä½¿ç”¨ â€œOverlap é‡å ç­–ç•¥â€åˆ‡åˆ†

ä¸ºäº†é¿å…åˆ‡åˆ†ç‚¹æŠŠå¥å­ã€æ¦‚å¿µã€å®šä¹‰ åˆ†å¼€ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨ï¼š

**ğŸ” é‡å  100ï½150 å­—**

ä¾‹å­ï¼š

chunk1ï¼šå†…å®¹A + å†…å®¹B + **éƒ¨åˆ†é‡å C**
 chunk2ï¼š**éƒ¨åˆ†é‡å C** + å†…å®¹D + å†…å®¹E

è¿™æ ·ä¿è¯ï¼š

- ä¸Šä¸‹æ–‡ä¸ä¸¢
- é€»è¾‘å¯ä»¥åœ¨ chunk ä¹‹é—´è¿ç»­ä¼ é€’
- RAGã€èšç±»ã€å¬å›æ•ˆæœæ›´ç¨³å®š

### æ ‡é¢˜

#### **é¢˜å¿…é¡»æ˜¯ä¸­æ–‡è¯­ä¹‰åŒ–æ ‡é¢˜ï¼Œä¸èƒ½ä¹±å†™ã€ä¸ç”¨å¤ªæ·±å±‚çº§ã€‚**

ä¸‹é¢æˆ‘æŠŠæœ€ä½³å®è·µç»™ä½ è®²æ¸…æ¥šã€‚

------

ğŸŸ© ä¸€ã€ä¸ºä»€ä¹ˆ `## / ###` å¤šçº§æ ‡é¢˜é€‚åˆ embeddingï¼Ÿ

å› ä¸º embedding æ¨¡å‹ï¼ˆå¦‚ BGEã€Qwenã€Seedï¼‰å…¶å®æ˜¯**è¯­è¨€æ¨¡å‹**ï¼Œå®ƒä»¬ä¼šç†è§£ï¼š

- `## åŸºç¡€ä¿¡æ¯` ä»£è¡¨ä¸€ä¸ªè¯­ä¹‰æ®µè½å¼€å§‹
- `## æ¶ˆè´¹è®°å½•` ä¸‹é¢æ˜¯æ¶ˆè´¹ç›¸å…³å†…å®¹
- `### åŒ»ç¾é¡¹ç›®æ¶ˆè´¹` æ˜¯æ›´ç»†ç²’åº¦åˆ†ç±»

æ ‡é¢˜ â†’ æ˜¯å¼ºè¯­ä¹‰ä¿¡å·ï¼Œä¼šè®© embedding æ›´æ¸…æ™°ã€‚

**ä¸åƒè¡¨æ ¼é‚£æ ·ä¼šç ´åå‘é‡è´¨é‡**ã€‚

æ‰€ä»¥ **æ ‡é¢˜ + åˆ—è¡¨** æ˜¯æœ€ä½³ç»„åˆã€‚

------

ğŸŸ§ äºŒã€æœ€æ¨èçš„ç»“æ„ï¼ˆä½ ç›´æ¥ç…§è¿™ä¸ªç”¨ï¼‰

ä¾‹å¦‚ä¸€ä¸ªç”¨æˆ·çš„å®Œæ•´è¡Œä¸ºï¼Œå¯ä»¥è¿™æ ·ç»„ç»‡ï¼š

```
## åŸºç¡€ä¿¡æ¯
- å¹´é¾„ï¼š28
- åŸå¸‚ï¼šåŒ—äº¬
- æ€§åˆ«ï¼šå¥³

## æ¶ˆè´¹è®°å½•
### åŒ»ç¾é¡¹ç›®æ¶ˆè´¹
- é¡¹ç›®ï¼šå…¨åˆ‡åŒçœ¼çš®ï¼›é‡‘é¢ï¼š7800 å…ƒï¼›æ—¥æœŸï¼š2023-09-12
- é¡¹ç›®ï¼šç¥›çœ¼è¢‹ï¼›é‡‘é¢ï¼š5200 å…ƒï¼›æ—¥æœŸï¼š2024-01-03

### çš®è‚¤é¡¹ç›®æ¶ˆè´¹
- é¡¹ç›®ï¼šçš®è‚¤ç®¡ç†ï¼›é‡‘é¢ï¼š398 å…ƒï¼›æ—¥æœŸï¼š2024-01-28

## æµè§ˆè¡Œä¸º
- æµè§ˆæ–‡ç« ï¼šã€Šå¼€çœ¼è§’éœ€ä¸éœ€è¦å…¨éº»ï¼Ÿã€‹
- æµè§ˆè§†é¢‘ï¼šã€ŠåŒçœ¼çš®ä¿®å¤æ¡ˆä¾‹è§£é‡Šã€‹
- æŸ¥çœ‹åŒ»ç”Ÿä¸»é¡µï¼šå¼ ä¸‰ï¼ˆçœ¼æ•´å½¢ï¼‰

## ç”¨æˆ·å‘è¨€
- â€œä¸Šæ¬¡åšçœ¼è¢‹æ¢å¤å¾—æœ‰ç‚¹æ…¢â€
- â€œåŒçœ¼çš®æœ‰æ²¡æœ‰è‡ªç„¶ä¸€ç‚¹çš„æ–¹æ¡ˆï¼Ÿâ€
```

è¿™æ˜¯ embeddingã€èšç±»ã€æœç´¢ã€ç”»åƒçš„ **é»„é‡‘ç»“æ„**ã€‚

------

ğŸŸ¦ ä¸‰ã€ä¸ºä»€ä¹ˆå»ºè®®æœ€å¤šåªç”¨ä¸¤çº§æ ‡é¢˜ï¼ˆ`##` å’Œ `###`ï¼‰ï¼Ÿ

å› ä¸ºï¼š

âœ” embedding æ¨¡å‹èƒ½å¾ˆå¥½ç†è§£ä¸¤çº§å±‚çº§ç»“æ„

ï¼ˆæ¯”å¦‚ ä¸€çº§ç±»åˆ« / äºŒçº§ç±»åˆ«ï¼‰

âš ï¸ ä½†ä¸‰çº§ä»¥ä¸Šï¼ˆ`####`ã€`#####`ï¼‰

æ¨¡å‹çš„æ³¨æ„åŠ›å¯èƒ½ä¼šé™ä½ï¼Œä¸å¦‚ä¸€çº§æ ‡é¢˜æ¸…æ™°ã€‚

#### æœ€ä¸æ¨èçš„æ ‡é¢˜å†™æ³•ï¼ˆé¿å…ï¼‰

ä¸‹é¢è¿™äº›ä¼šç ´å embeddingï¼š

âŒ è‹±æ–‡æ ‡é¢˜ï¼ˆembedding ä¼šåç§»å‘é‡ç©ºé—´ï¼‰

```
## Basic info
## Transactions
```

âŒ å¤ªæŠ€æœ¯åŒ–æ ‡é¢˜

```
## key:value data
## structured table
```

âŒ å¤ªæ·±å±‚çº§ï¼ˆè¶…è¿‡ä¸‰çº§ï¼‰

```
######
```

âŒ æ ‡é¢˜ä¸ç»Ÿä¸€ã€éšæ„ä¹±å†™

embedding ä¸ç¨³å®šã€‚

### åˆ—è¡¨

#### æœ€æ¨èçš„æ ¼å¼ï¼ˆä½ ç›´æ¥ç…§åš â†’ embedding æœ€ç¨³å®š + èšç±»æœ€å‡†ç¡®ï¼‰

âœ… ä¸€ã€é¡¶å±‚ç”¨ Markdown åˆ—è¡¨

âœ… äºŒã€å¤šæ¡è®°å½•ç”¨â€œåµŒå¥—åˆ—è¡¨ / è¿ç»­åˆ—è¡¨â€å³å¯

âœ… ä¸‰ã€æœ€å¤šç”¨ä¸¤çº§ï¼ˆä¸€çº§/äºŒçº§ï¼‰å³å¯ï¼Œåƒä¸‡ä¸è¦è¶…è¿‡ä¸‰çº§ã€‚

â— ä¸è¦åˆå¹¶æˆä¸€è¡Œï¼Œä¸è¦ç”¨è¡¨æ ¼ï¼Œä¹Ÿä¸è¦ç”¨ key:value

ç¤ºä¾‹ç”¨æˆ·æ¶ˆè´¹è®°å½•ï¼ˆå¤šæ¡ï¼‰ğŸ‘‡

```
- æ¶ˆè´¹è®°å½•ï¼š
  - é¡¹ç›®ï¼šå…¨åˆ‡åŒçœ¼çš®ï¼›é‡‘é¢ï¼š7800 å…ƒï¼›æ—¥æœŸï¼š2023-09-12
  - é¡¹ç›®ï¼šç¥›çœ¼è¢‹ï¼›é‡‘é¢ï¼š5200 å…ƒï¼›æ—¥æœŸï¼š2024-01-03
  - é¡¹ç›®ï¼šçš®è‚¤ç®¡ç†ï¼›é‡‘é¢ï¼š398 å…ƒï¼›æ—¥æœŸï¼š2024-01-28
```

ä¸ºä»€ä¹ˆæ•ˆæœå¥½ï¼Ÿ

- åµŒå¥—åˆ—è¡¨ç»“æ„ â†’ embedding æ¨¡å‹èƒ½å¾ˆå¥½ç†è§£â€œå¤šä¸ªç‹¬ç«‹äº‹ä»¶â€
- æ¯æ¡äº‹ä»¶æ˜¯è‡ªç„¶è¯­ä¹‰å¥å­ â†’ èšç±»æ•ˆæœæ›´æ¸…æ™°
- ä¸å¼•å…¥è¡¨æ ¼å’Œ key:value å™ªå£°
- å…¨ä¸­æ–‡ â†’ è¿›å…¥ä¸­æ–‡ embedding ç©ºé—´ä¸€è‡´æ€§å¼º

## éƒ¨ç½²

```
ollama pull bge-m3
```

# LLM

**ç”¨æˆ·ç”»åƒï¼ˆé”€å”®è®°å½•ã€è¡Œä¸ºè®°å½•ã€èŠå¤©å‘è¨€åˆ†æï¼‰** å’Œ **ä½ çš„ç¡¬ä»¶ï¼š4090ï¼ˆ24GBï¼‰** æ¥ç›´æ¥ç»™ä½ **æœ€æ¨èçš„ LLM æ–¹æ¡ˆ**ã€‚

ä¸‹é¢æ˜¯â€œåªçœ‹æ•ˆæœ + æ€§èƒ½ + æ˜¾å­˜ + æ€§ä»·æ¯”â€ä¸‹çš„**æœ€ä¼˜æ¨è**ã€‚

------

## ğŸŸ© **ğŸ”¥ æœ€æ¨èï¼ˆå¼ºçƒˆæ¨èï¼‰**

### **Qwen2.5-7B (4-bit é‡åŒ–)**

ğŸ‘‰ **ç”¨æˆ·ç”»åƒåœºæ™¯çš„ç¬¬ä¸€é€‰æ‹©**

ä¸ºä»€ä¹ˆæœ€æ¨èï¼Ÿ

- è¯­ä¹‰ç†è§£åŠ›éå¸¸å¼ºï¼ˆæ¯” Yi 1.5ã€Llama3 8B åœ¨ä¸­æ–‡åœºæ™¯æ˜æ˜¾æ›´å¼ºï¼‰
- ç‰¹åˆ«æ“…é•¿ï¼šåˆ†æç”¨æˆ·æ„å›¾ã€è¡Œä¸ºæ¨¡å¼ã€æƒ…ç»ªæ¨æ–­
- 4090 ä¸Š 4-bit è·‘å¾—éå¸¸å¿«ï¼ˆ60â€“90 tok/sï¼‰
- æ˜¾å­˜åªéœ€ï¼š**6GB**
- æ€§ä»·æ¯”æœ€é«˜

åœºæ™¯é€‚é…ï¼š

- ç”¨æˆ·æ ‡ç­¾ç”Ÿæˆ
- ç”¨æˆ·å…´è¶£æ€»ç»“
- æ ¹æ®è¡Œä¸º/å‘è¨€åšç”»åƒ
- ç”Ÿæˆæ¨èç†ç”±
- å¼‚å¸¸è¡Œä¸ºåˆ†æ
- é¢„æµ‹ç”¨æˆ·ä¸‹ä¸€æ­¥åŠ¨ä½œï¼ˆè´­ä¹°æ„å›¾ï¼‰

**å¦‚æœä½ åªæƒ³é€‰ä¸€ä¸ª â†’ å°±é€‰è¿™ä¸ªã€‚**

------

## ğŸŸ¦ **æ¬¡æ¨èï¼ˆæ›´å¼ºä¸€ç‚¹ï¼Œä½†æ›´è´µï¼‰**

### **Qwen2.5-14B (4-bit é‡åŒ–)**

å¦‚æœä½ å¸Œæœ› **æ›´æ·±åº¦æ¨ç†ã€æ›´ç²¾ç»†ç”»åƒ** â†’ ç”¨è¿™ä¸ªã€‚

### ä¼˜ç‚¹

- ä¸­æ–‡èƒ½åŠ›æ¯” 7B å†ä¸Šä¸€æ¡£
- äººç‰©ç”»åƒã€æƒ…ç»ªè¯†åˆ«ã€é•¿æ–‡æœ¬æ€»ç»“æ›´å¼º
- æ¨ç†åŠ›æ¥è¿‘ GPT-4 çº§åˆ«çš„è½»é‡ç‰ˆ

### ç¼ºç‚¹

- æ˜¾å­˜å ç”¨ï¼š**10â€“12GB**
- å•æ¨é€Ÿåº¦æ¯” 7B ç¨æ…¢ï¼Œä½†ä»ç„¶èƒ½è·‘

### åœºæ™¯é€‚é…ï¼š

- é«˜ç²¾åº¦ç”¨æˆ·ç”»åƒï¼ˆå¦‚é‡‘èã€ç”µå•†ã€è™šæ‹Ÿå®¢æœï¼‰
- å¤§æ®µé”€å”®å¯¹è¯åˆ†æ
- å¤šæ¨¡æ€æ¨æ–­ï¼ˆå¦‚ç»“åˆè¡Œä¸º+æ–‡æœ¬ï¼‰

## q4_k_m æ¯” q4_0 åŒºåˆ«

```
ollama pull qwen2.5:14b-instruct-q4_K_M
```



**ç»“è®ºï¼ˆä¸€å¥è¯ï¼‰**

**q4_k_m æ¯” q4_0 æ›´å¼ºã€æ›´å‡†ã€æ¨ç†æ›´ç¨³ï¼Œä½†æ˜¾å­˜å ç”¨æ›´é«˜ä¸€ç‚¹ã€‚
 q4_0 æ›´è½»ã€æ›´çœæ˜¾å­˜ï¼Œä½†æ•ˆæœç¨å¼±ä¸€äº›ã€‚**

ä½ åªè¦è®°ä½ï¼š

ğŸ‘‰ **è¦æ•ˆæœ â†’ ç”¨ q4_k_m**
 ğŸ‘‰ **è¦é€Ÿåº¦/è½»é‡ â†’ ç”¨ q4_0**

# æ•´ä½“ç»“æ„

ä¸‹é¢æˆ‘ä¼šç”¨ **ä½ çš„ç¡¬ä»¶ï¼ˆRTX 4090ï¼‰+ ä»»åŠ¡ç±»å‹ï¼ˆç”¨æˆ·ç”»åƒï¼Œåˆ†æç”¨æˆ·é”€å”®/è¡Œä¸º/å‘è¨€è®°å½•ï¼‰** ä¸ºå‰æï¼Œç»™å‡ºï¼š

1. æ˜¯å¦é€‚åˆéƒ¨ç½² **BGE-M3ï¼ˆæˆ– BGE3ï¼‰+ LLM + reranker**
2. æ˜¾å­˜æ˜¯å¦è¶³å¤Ÿã€æ˜¯å¦ä¼šçˆ†
3. QPS å¤§æ¦‚èƒ½åˆ°å¤šå°‘
4. æ¨èçš„æœ€ä½³ç»“æ„ä¸é‡åŒ–æ–¹æ¡ˆ

å†…å®¹åŸºäºç»éªŒå’Œä½ æœºå™¨çš„å®é™…ç¡¬ä»¶èƒ½åŠ›ï¼ˆ4090 = 24GB VRAMï¼‰ã€‚

## âœ… ä¸€ã€ä½ çš„åœºæ™¯éå¸¸é€‚åˆ

### âœ”ï¸ ç”¨æˆ·ç”»åƒï¼ˆUser Profilingï¼‰

éœ€è¦ embedding â†’ èšç±» â†’ ç”¨æˆ·ç‰¹å¾ â†’ æ¨è/é¢„æµ‹ â†’ LLM åˆ†ææ€»ç»“
 ä½ çš„éœ€æ±‚éå¸¸å…¸å‹ã€‚

### âœ”ï¸ å¯ç”¨æ¶æ„ï¼š

```
[Embedding: BGE-M3 or BGE-Large]
        â†“
[Reranker: BGE-reranker-v2 or Cohere Reranker]
        â†“
[LLM: GPT 4o mini / Qwen2.5 14B]
```

**éå¸¸é€‚åˆï¼ä½ å®Œå…¨èƒ½éƒ¨ç½²è¿™ä¸€å¥—æ¶æ„ã€‚**

------

## âœ… äºŒã€4090 æ˜¾å­˜èƒ½ä¸èƒ½æ’‘å¾—ä½ï¼Ÿ

### 1. **BGE-M3ï¼ˆembeddingï¼‰**

- FP16 å¤§çº¦å ï¼š**1.2â€“1.4GB**
- INT8 or 4-bit é‡åŒ–å â†’ **400â€“800MB**

### 2. **Rerankerï¼ˆBGE-reranker-large / v2ï¼‰**

- FP16 æ—¶å¤§çº¦ï¼š**2.0â€“2.5GB**
- INT8 åï¼š**1.0â€“1.3GB**

### 3. **LLMï¼ˆæ ¹æ®ä½ é€‰æ‹©ï¼‰**

| æ¨¡å‹        | FP16æ˜¾å­˜        | æ¨èé‡åŒ– | é‡åŒ–åæ˜¾å­˜          |
| ----------- | --------------- | -------- | ------------------- |
| Qwen2.5-7B  | ~14GB           | 4bit     | **6GB**             |
| Qwen2.5-14B | ~28GBï¼ˆè£…ä¸ä¸‹ï¼‰ | 4bit     | **10â€“12GB**ï¼ˆå¯ä»¥ï¼‰ |
| Yi-1.5-9B   | ~18GB           | 4bit     | **8GB**             |

### âœ” æ€»æ˜¾å­˜é¢„ç®—ï¼ˆä¾‹ï¼‰

ä»¥â€œ7B LLM + BGE-M3 + rerankerâ€ä¸ºä¾‹ï¼ˆéƒ½é‡åŒ–ï¼‰ï¼š

| æ¨¡å—            | æ˜¾å­˜       |
| --------------- | ---------- |
| BGE-M3 (INT8)   | ~0.7GB     |
| Reranker (INT8) | ~1.2GB     |
| 7B LLM (4bit)   | ~6GB       |
| å…¶ä»–ç¼“å­˜        | ~1â€“2GB     |
| **æ€»è®¡**        | **9â€“10GB** |

### ğŸ‘‰ ç»“è®º

**ä¸ä¼šçˆ†æ˜¾å­˜ã€‚4090 éƒ¨ç½²ä¸€æ•´å¥—ï¼šæ²¡é—®é¢˜ã€‚**

å¦‚æœä½ ç”¨ 14B LLMï¼ˆ4bitï¼‰ï¼Œæ˜¾å­˜ä¼šåˆ° 12-14GBï¼Œä¹Ÿèƒ½è·‘ã€‚

------

## ğŸš€ ä¸‰ã€QPS å¯ä»¥è¾¾åˆ°å¤šå°‘ï¼Ÿï¼ˆéå¸¸é‡è¦ï¼‰

ä»¥ä¸‹ä¸ºâ€œå•å¡ 4090 + 24GBæ˜¾å­˜â€çš„çœŸå®å¯è¾¾èŒƒå›´ï¼ˆç»éªŒå€¼ï¼‰

------

### âœ… **Embeddingï¼ˆBGE-M3ï¼‰QPS**

- FP16ï¼š**3500â€“5000 QPS**ï¼ˆçŸ­æ–‡æœ¬ï¼‰
- INT8ï¼š**6000+ QPS**

ç”¨äºç”¨æˆ·è¡Œä¸º/å‘è¨€/è®°å½• â†’ éå¸¸å¤Ÿç”¨

------

### âœ… **Reranker QPSï¼ˆBGE-reranker-v2ï¼‰**

reranker æ˜¯ pipeline æœ€æ…¢çš„æ¨¡å—ï¼š

- FP16ï¼š**40â€“60 QPS**
- INT8ï¼š**70â€“90 QPS**

å¤§å¤šæ•°ä¸šåŠ¡ QPS ç“¶é¢ˆåœ¨ rerankerï¼Œä¸åœ¨ embeddingã€‚

------

### âœ… **LLMï¼ˆ7Bâ€“14Bï¼‰æœ¬åœ°æ¨ç† QPS**

æŒ‰ token/s æ¢ç®—ï¼š

### **7Bï¼ˆQwen2.5 / Yiï¼‰**

- ç”Ÿæˆé€Ÿåº¦ï¼š**60â€“90 tok/s**
- å…¸å‹å¯¹è¯ï¼š0.2~0.4s å“åº”

è‹¥ä½ æ˜¯â€œæ¯æ¡ç”¨æˆ·äº‹ä»¶åš LLM åˆ†æâ€ï¼ŒQPS å¯è¾¾ï¼š

ğŸ‘‰ **QPS â‰ˆ 3â€“4**

### **14Bï¼ˆQwen2.5 14B 4bitï¼‰**

- ç”Ÿæˆé€Ÿåº¦ï¼š**35â€“50 tok/s**

ğŸ‘‰ **QPS â‰ˆ 2â€“3**

### å¦‚æœæ˜¯æ‰¹å¤„ç†ï¼ˆç¦»çº¿æ„å»ºç”¨æˆ·ç”»åƒï¼‰

- **å¯ä»¥åˆ° 10â€“20 QPS**

------

## ğŸ’¡ å››ã€çœŸæ­£çš„ç“¶é¢ˆåœ¨å“ªé‡Œï¼Ÿ

å¦‚æœä½ è¿™æ ·æµç¨‹ï¼š

```
ç”¨æˆ·è¡Œä¸º â†’ embedding â†’ å‰100å€™é€‰ â†’ reranker â†’ LLMè§£é‡Š
```

ç“¶é¢ˆæ˜¯ï¼š

1) rerankerï¼ˆ70â€“90 QPSï¼‰

2) LLMï¼ˆçº¦ 3 QPSï¼‰

å› æ­¤ä½ å®é™…åœ¨çº¿ QPSï¼š

ğŸ‘‰ **æ•´ä½“ end-to-end åœ¨çº¿ QPS â‰ˆ 2â€“3ï¼ˆå•å¡ 4090ï¼‰**

å¦‚æœä½ æ˜¯ **æ‰¹é‡ç¦»çº¿æ„å»ºç”¨æˆ·ç”»åƒ**ï¼Œé‚£ä¹ˆå¯ä»¥ï¼š

ğŸ‘‰ **embedding QPS 5000+**

ğŸ‘‰ **reranker QPS 90**

ğŸ‘‰ **LLM å¯å¤šçº¿ç¨‹è·‘åˆ° 10â€“20 QPS**



# å…¶ä»–

## åˆ†å¡è¿è¡Œ

æ˜ç™½ï¼Œä½ æ˜¯åœ¨ **Linux Mint ä¸Šè¿è¡Œ Ollamaï¼ˆä½œä¸ºç³»ç»ŸæœåŠ¡ ollama.serviceï¼‰**ï¼Œ
 è€Œä¸æ˜¯é€šè¿‡ä¸¤ä¸ª shell ç¯å¢ƒå»è·‘ä¸¤ä¸ªç‹¬ç«‹çš„ Ollama å®ä¾‹ã€‚

âš ï¸ **é‡ç‚¹ï¼šOllama æ˜¯å•å®ä¾‹æœåŠ¡ï¼Œä¸æ”¯æŒåŒæ—¶ä»¥ä¸åŒç¯å¢ƒå˜é‡â€œå¼€ä¸¤å¥— Ollama æœåŠ¡â€ã€‚**
 æ‰€ä»¥â€œå¼€ä¸¤ä¸ªç»ˆç«¯åˆ†åˆ«è®¾ç½®ç¯å¢ƒå˜é‡â€**å¯¹ç³»ç»Ÿçº§ Ollama æœåŠ¡æ˜¯æ— æ•ˆçš„**ã€‚

ä½†â€”â€”
 æˆ‘å¯ä»¥æ•™ä½ **æ­£ç¡®æ–¹å¼**è®©ï¼š

- **å¤§æ¨¡å‹ï¼ˆQwen3-32Bï¼‰ç”¨ GPU**
- **Embedding æ¨¡å‹ç”¨ CPU + å†…å­˜**

å¹¶ä¸”ä¸¤è€…ä¸ä¼šäº’ç›¸å½±å“ã€‚

------

### **æ–¹æ¡ˆ Aï¼ˆæœ€ç®€å• ï¼‰â€”â€” embedding æ—¶ä¸´æ—¶ç¦ç”¨ GPUï¼ˆæ¨èç”Ÿäº§ï¼‰**

Ollama å…è®¸ä½ åœ¨ **æ¯ä¸ª API è¯·æ±‚ä¸­æŒ‡å®šæ˜¯å¦ä½¿ç”¨ GPU**ã€‚

**curl è¯·æ±‚ä¸­åŠ å…¥ï¼š `"options":{"num_gpu":0}`**

ğŸ‘‡ **Embedding èµ° CPUï¼š**

```
curl http://localhost:11434/api/embeddings \
  -d '{
    "model": "qwen3-embedding:0.6b",
    "prompt": "ä½ å¥½",
    "options": {
      "num_gpu": 0
    }
  }'
```

â†’ **è¿™æ ·å³ä½¿ ollama æœåŠ¡å¯ç”¨äº† GPUï¼ŒæŸä¸ªæ¨¡å‹ä¹Ÿå¯ä»¥å¼ºåˆ¶èµ° CPUã€‚**
 â†’ ä¸éœ€è¦ä¸¤ä¸ª Ollama å®ä¾‹ï¼Œä¸æ”¹ç¯å¢ƒå˜é‡ï¼Œä¸æ”¹ systemdã€‚

------

### **æ–¹æ¡ˆ B â€”â€” åœ¨ Python/Node é‡ŒæŒ‡å®š embedding ç”¨ CPU**

Pythonï¼š

```
import ollama

res = ollama.embeddings(
    model='qwen3-embedding:0.6b',
    prompt='hello',
    options={"num_gpu": 0}
)
```

Nodeï¼š

```
const res = await ollama.embeddings({
  model: 'qwen3-embedding:0.6b',
  prompt: 'hello',
  options: { num_gpu: 0 }
})
```

------

### **æ–¹æ¡ˆ C â€”â€” é’ˆå¯¹æŸä¸ªæ¨¡å‹æ°¸ä¹…è®¾ç½® CPU æ¨ç†ï¼ˆ.ollama/models ä¸­é…ç½®ï¼‰**

Ollama æ”¯æŒåœ¨ **æ¨¡å‹ modelfile** ä¸­å†™æ­»å¼ºåˆ¶ CPUï¼š

åˆ›å»ºä¸€ä¸ª CPU-only embedding æ¨¡å‹ï¼š

1. æ–°å»ºæ–‡ä»¶ï¼š

```
qwen3-emb-cpu.Modelfile
```

å†…å®¹ï¼š

```
FROM qwen3-embedding:0.6b
PARAMETER num_gpu 0
```

1. å¯¼å…¥ï¼š

```
ollama create qwen3-embedding-cpu -f qwen3-emb-cpu.Modelfile
```

1. ä½¿ç”¨ï¼š

```
ollama embeddings --model qwen3-embedding-cpu --prompt "hello"
```

â†’ **åªå½±å“ embedding æ¨¡å‹ï¼Œä¸å½±å“ä½ çš„ 32B å¤§æ¨¡å‹ã€‚**



## é…ç½®

    payload = {
        "model": LLM_MODEL,
        "prompt": prompt,
        "stream": False,
        "think": False, # å…³é—­æ·±åº¦æ€è€ƒ
        "options": {
            "num_ctx": 20960, # æœ€å¤šä¸Šä¸‹æ–‡ 20960
            "num_predict": 8000, # æœ€å¤šç”Ÿæˆ 8000 tokens
        },
    }

## è¿”å›

è¿”å›é‡Œçš„ï¼š

```
"prompt_eval_count": 20960
"eval_count": 447
```

 Ollama çš„å®˜æ–¹å­—æ®µï¼š

- `prompt_eval_count` â†’ æ¨¡å‹å¯¹ prompt åˆ†è¯åè¯„ä¼°çš„ token æ•°
- `eval_count` â†’ æ¨¡å‹ç”Ÿæˆçš„ token æ•°
- `eval_duration` / `prompt_eval_duration` â†’ æ¨ç†æ¶ˆè€—æ—¶é—´
- `load_duration` â†’ åŠ è½½æ¨¡å‹æ—¶é—´



# æŠ¥é”™

## ollama å¹¶å‘

> æ³¨æ„, ollama å¹¶å‘ä¼šæ”¹æ‰æ‰€æœ‰ ollama æ¨¡å‹çš„æ˜¾å­˜å ç”¨
>
> æ‰€ä»¥éœ€è¦å¹¶å‘çš„æ¨¡å‹, è¯·ä½¿ç”¨ vllm æˆ–è€… sglang

+ ç¼–è¾‘ ` sudo sublime /etc/systemd/system/ollama.service  `

  æ³¨æ„, éœ€è¦æ”¾åœ¨ [Service] ä¸­, [Install] ä¹‹å‰

  ```
  [Service]
  Environment="OLLAMA_NUM_PARALLEL=4"
  Environment="OLLAMA_MAX_LOADED_MODELS=2"
  ```

+ ```
  sudo systemctl daemon-reload
  sudo systemctl restart ollama
  ```

## ip ä¸èƒ½è®¿é—®

```
docker logs dify-api validated_credentials = model_provider_factory.model_credentials_validate(

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

File "/app/api/core/model_runtime/model_providers/model_provider_factory.py", line 156, in model_credentials_validate

self.plugin_model_manager.validate_model_credentials(

File "/app/api/core/plugin/impl/model.py", line 137, in validate_model_credentials

for resp in response:

^^^^^^^^

File "/app/api/core/plugin/impl/base.py", line 278, in _request_with_plugin_daemon_response_stream

self._handle_plugin_daemon_error(error.error_type, error.message)

File "/app/api/core/plugin/impl/base.py", line 308, in _handle_plugin_daemon_error

raise CredentialsValidateFailedError(error_object.get("message"))

core.model_runtime.errors.validate.CredentialsValidateFailedError: An error occurred during credentials validation: HTTPConnectionPool(host='172.16.69.222', port=11434): Max retries exceeded with url: /api/embed (Caused by NewConnectionError("HTTPConnection(host='172.16.69.222', port=11434): Failed to establish a new connection: [Errno 111] Connection refused")) docker logs dify-api
```

This error indicates that your **Dify API container** cannot connect to the **Ollama** service running at the IP address `172.16.69.222` on port `11434`.

The specific error is `[Errno 111] Connection refused`, which usually means the server (Ollama) is active but rejecting the connection, or it is not listening on that specific IP address.

Here is the step-by-step solution to fix this.

------

1. The Root Cause: Ollama Binding

By default, Ollama binds only to `127.0.0.1` (localhost). This means it will only accept connections from the machine it is running on.

However, your Dify container is a separate "machine" (virtually) trying to access Ollama via the network IP (`172.16.69.222`). Because Ollama is only listening on localhost, it refuses the connection from the Dify container.

2. The Fix: Expose Ollama to the Network

You need to change the environment variable `OLLAMA_HOST` to `0.0.0.0` so that Ollama listens on all network interfaces.

**If running Ollama on Linux/Mac:**

1. Stop the current Ollama process.

2. Set the environment variable and restart Ollama:

   Bash

   ```
   OLLAMA_HOST=0.0.0.0 ollama serve
   ```

**If running Ollama as a Systemd Service (Linux):**

1. Edit the systemd service file:

   Bash

   ```
   sudo sublime /etc/systemd/system/ollama.service
   ```

2. Add the environment variable under the `[Service]` section:

   Ini, TOML

   ```
   [Service]
   Environment="OLLAMA_HOST=0.0.0.0"
   ```

3. Save and exit.

4. Reload and restart the service:

   Bash

   ```
   sudo systemctl daemon-reload
   sudo systemctl restart ollama
   ```

## Ollama Dify é›†æˆ Embed Model

Ollama context size: `ollama show xxxmodel`

Dify-Ollama-Context-Size: Model->Context Size: é»˜è®¤4096

Dify Config:

```
# web å’Œ api éƒ½ä¿®æ”¹
INDEXING_MAX_SEGMENTATION_TOKENS_LENGTH = 4096
```



## USB ollama pull æ— å“åº”

+ ä¸€åˆ†é’Ÿå®šä½

  ```
  ç”¨ 1 åˆ†é’Ÿå®šä½åˆ°åº•æ˜¯å“ªä¸€ç§ï¼ˆåœ¨â€œæ‰‹æœºçƒ­ç‚¹ USBâ€çŠ¶æ€ä¸‹è·‘ï¼‰
  
  è¿™äº›å‘½ä»¤ä¸ä¼šæ”¹é…ç½®ï¼Œåªæ˜¯æµ‹ç½‘ç»œ
  
  # 1) çœ‹é»˜è®¤è·¯ç”± / ä½ ç°åœ¨èµ°å“ªå¼ ç½‘å¡
  ip route
  
  # 2) çœ‹ registry åŸŸåè§£æåˆ°äº†å“ªäº›åœ°å€ï¼ˆåŒæ—¶çœ‹ v4/v6ï¼‰
  getent ahosts registry.ollama.ai
  getent ahosts registry-1.docker.io   # å¦‚æœä½ è¯´çš„â€œæ‹‰é•œåƒâ€æ˜¯ docker
  
  # 3) åˆ†åˆ«å¼ºåˆ¶ IPv4 / IPv6 è®¿é—®æµ‹è¯•ï¼ˆå¾ˆå…³é”®ï¼‰
  curl -4Iv https://registry.ollama.ai/v2/
  curl -6Iv https://registry.ollama.ai/v2/
  
  # 4) ç²—æµ‹ MTUï¼ˆ1472 å¯¹åº” 1500 MTUï¼›å¤±è´¥å°±å¾ˆåƒ MTU/PMTU é—®é¢˜ï¼‰
  ping -M do -s 1472 1.1.1.1 -c 3
  ```

+ å¸¸è§å¤„ç†åŠæ³•

  ```
  ç«‹åˆ»å¯ç”¨çš„è§£å†³åŠæ³•ï¼ˆä¸´æ—¶ï¼‰
  
  ä½ ç°åœ¨é»˜è®¤èµ°çš„ USB ç½‘å¡æ˜¯ï¼š
  
  dev enx56f85e3448e4
  
  æŠŠå®ƒ MTU è°ƒåˆ° 1400ï¼ˆå¦‚æœä½ è¿˜å¥—äº†ä»£ç†/VPNï¼Œå»ºè®® 1380 æ›´ç¨³ï¼‰ï¼š
  
  sudo ip link set dev enx56f85e3448e4 mtu 1400
  # æˆ–è€…æ›´ä¿å®ˆä¸€ç‚¹
  # sudo ip link set dev enx56f85e3448e4 mtu 1380
  ```

  