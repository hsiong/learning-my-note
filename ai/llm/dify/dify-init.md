# initial

+ é¡¹ç›®ä¸èƒ½æ”¾åœ¨ç§»åŠ¨ç›˜ æ‡‚äº†å—

  å…¸å‹çš„ Postgres åœ¨å®¹å™¨é‡Œå°è¯• chmod 700 å¤±è´¥ï¼šä½ çš„ /var/lib/postgresql/data/pgdata æ˜ å°„åˆ°äº†å®¿ä¸»æœºçš„ NTFS/exFAT ä¹‹ç±»ä¸æ”¯æŒ Unix æƒé™çš„æ–‡ä»¶ç³»ç»Ÿï¼Œæˆ–è€…ç»‘å®šçš„æ˜¯ä¸ªä¸å…è®¸ chmod çš„è·¯å¾„ï¼Œæ‰€ä»¥æŠ¥

+ ä½¿ç”¨é¡¹ç›®ä¸“å± venv

  uv çš„è®¾è®¡ç†å¿µæ˜¯ï¼šæ¯ä¸ªé¡¹ç›®ç‹¬ç«‹ã€å¯å¤ç°ã€ä¸æ±¡æŸ“ç³»ç»Ÿç¯å¢ƒã€‚æ‰€ä»¥ï¼šå®ƒä¼šä¸ºæ¯ä¸ªé¡¹ç›®åˆ›å»ºä¸€ä¸ª .venv/ï¼ˆæˆ–è€…ä½ é…ç½®çš„è™šæ‹Ÿç¯å¢ƒç›®å½•ï¼‰ã€‚ä¾èµ–å…¨éƒ¨å®‰è£…åˆ°è¿™ä¸ªè™šæ‹Ÿç¯å¢ƒçš„ lib/pythonX.Y/site-packages ä¸‹ã€‚æ¿€æ´»è¯¥è™šæ‹Ÿç¯å¢ƒåï¼ŒPython / pip / uv éƒ½åªçœ‹åˆ°é¡¹ç›®è‡ªå·±çš„ä¾èµ–ã€‚è¿™æ ·ï¼šä¸ä¼šå’Œç³»ç»Ÿ Python å†²çªï¼›ä¸åŒé¡¹ç›®å¯ä»¥ç”¨ä¸åŒç‰ˆæœ¬çš„ Flaskã€Djangoã€Numpy ç­‰ï¼›é¡¹ç›®å¯å¤ç°ï¼ˆåˆ«äºº uv sync ä¸€ä¸‹å°±èƒ½å¤ç°ç¯å¢ƒï¼‰ã€‚

## middleware

+ init

  ```
  cp .env.example .env
  cp middleware.env.example middleware.env
  cp docker-compose.middleware.yaml docker-compose.middleware.copy.yaml
  ```

+ modify config `.env & middleware.env`

  ```
  PIP_MIRROR_URL=https://pypi.tuna.tsinghua.edu.cn/simple
  ```

+ shell

  ```
  
  cd docker
  
  # sandbox: https://github.com/langgenius/dify/issues/23365
  docker compose -f docker-compose.middleware.copy.yaml  down
  sudo find ./volumes -mindepth 1 ! -path "*/sandbox*" -exec rm -rf {} + && \
  sudo find ../api/storage -mindepth 1 ! -path "*/sandbox*" -exec rm -rf {} +
  
  ps aux | grep celery | grep -v grep | awk '{print $2}' | xargs kill -9
  docker compose -f docker-compose.middleware.copy.yaml  up -d
  ```

  

### sandbox error: open conf/config.yaml: no such file or directory panic:   

```
docker logs  docker-sandbox-1
2025/11/07 13:02:19 server.go:18: [PANIC]failed to init config: open conf/config.yaml: no such file or directory panic:   
```

https://github.com/langgenius/dify/issues/23365

## web

+ ```
  cd web
  cp .env.example .env.local
  ```

+ Modify the values of these environment variables according to your requirements

  ```
  NEXT_PUBLIC_CSP_WHITELIST=https://marketplace.dify.ai localhost
  ```

+ shell

  ```shell
  cd ../web
  brew install node@22
  brew unlink node@16
  brew link --overwrite node@22
  echo 'export PATH="/opt/homebrew/opt/node@22/bin:$PATH"' >> ~/.zshrc
  source ~/.zshrc
  sudo fuser -k 3000/tcp #kill port
  
  
  rm -rf node_modules pnpm-lock.yaml package-lock.json
  pnpm install
  pnpm run build
  pnpm start
  
  
  # don't use proxy
  # install plugin from local & wait to install
  ```

## api-repo

+ api å•ç‹¬ä½œä¸ºé¡¹ç›®æ‰“å¼€

+ init

  ```
  cd api
  cp .env.example .env
  awk -v key="$(openssl rand -base64 42)" '/^SECRET_KEY=/ {sub(/=.*/, "=" key)} 1' .env > temp_env && mv temp_env .env
  ```

+ modify config

  ```sh
  sublime .env
  ENABLE_REQUEST_LOGGING=True
  SQLALCHEMY_ECHO=true # sql log
  ```

+ repo

  ```
  pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple && pip config set global.proxy http://127.0.0.1:7897
  pip install uv
  
  uv sync --group storage --group tools --group vdb --group dev \
    --index-url https://pypi.tuna.tsinghua.edu.cn/simple
  #pip install poetry
  #poetry install
  
  flask db upgrade
  celery -A app.celery worker -P gevent -c 1 --loglevel INFO -Q dataset,generation,mail,ops_trace
  flask run --host 0.0.0.0 --port=5001 --debug
  ```

## Pycharm è¿è¡Œ

### Pycharm web

package.json -> show npm scripts -> start -> run  

### PyCharm è¿è¡Œ Celery worker

1. api ä½œä¸ºå•ç‹¬é¡¹ç›®æ‰“å¼€

2. **ç‚¹å¼€å³ä¸Šè§’çš„å°ä¸‰è§’æ—è¾¹çš„ä¸‹æ‹‰ â†’ Edit Configurationsâ€¦**

3. ç‚¹å·¦ä¸Šè§’çš„â€œ+â€æ–°å»ºä¸€ä¸ª**Python**ç±»å‹çš„é…ç½®ã€‚

4. é…ç½®å¦‚ä¸‹å†…å®¹ï¼š

   - **Python interpreter**ï¼š

     - é€‰æ‹©ä½ çš„è™šæ‹Ÿç¯å¢ƒ Python

   - **Name**ï¼šéšä¾¿ï¼Œæ¯”å¦‚ `Celery worker`

   - **Script path**ï¼šå¡«å…¥ celery å¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„ï¼ˆé€šå¸¸æ˜¯ä½ çš„ venv é‡Œçš„ celery è„šæœ¬ï¼Œæ¨èç”¨ç»å¯¹è·¯å¾„ï¼Œå¦‚æœç”¨ pyenv/poetry/uv ä¹Ÿè¦é€‰ venv ä¸‹çš„ celeryï¼‰

     - ä½ å¯ä»¥ `which celery` æ‰¾åˆ°è·¯å¾„ï¼Œæ¯”å¦‚ `/Users/vjf/Projects/python/dify-prod/api/.venv/bin/celery`

   - **Parameters**ï¼š

     ```sh
     -A app.celery worker -P gevent -c 1 --loglevel INFO -Q dataset,generation,mail,ops_trace
     ```

   - **Working directory**ï¼š

     - ä½ çš„é¡¹ç›®æ ¹ç›®å½•ï¼Œæ¯”å¦‚ `/Users/vjf/Projects/python/dify-prod/api`

#### ç”¨ â€œPythonâ€ é…ç½®è·‘ `python -m flask â€¦`ï¼ˆä¸éœ€è¦ run.pyï¼‰

1. æ‰“å¼€ï¼š**Run â†’ Edit Configurationsâ€¦**
2. å·¦ä¸Šè§’ **â•** â†’ é€‰ **Python**
3. åœ¨å³ä¾§æŒ‰ä¸‹é¢å¡«ï¼š

- **Name**ï¼š`Flask (python -m)`
- **Module name**ï¼š`flask`  â† å‹¾é€‰ *Module name*ï¼ˆä¸æ˜¯ Script pathï¼‰
- **Parameters**ï¼š`run --host=0.0.0.0 --port=5001 --debug`
- **Working directory**ï¼šä½ çš„é¡¹ç›®æ ¹ç›®å½•ï¼ˆåŒ…å« `app/` ç›®å½•çš„é‚£å±‚ï¼‰
- **Python interpreter**ï¼šé€‰æ‹©é¡¹ç›®çš„è™šæ‹Ÿç¯å¢ƒï¼ˆ`.venv`ï¼‰
- **Environment variables**ï¼ˆå…³é”®ï¼‰ï¼š
  - `FLASK_APP=app`  æˆ– `FLASK_APP=app:create_app`ï¼ˆçœ‹ä½ é¡¹ç›®ç»“æ„ï¼‰
  - `FLASK_ENV=development`
  - ï¼ˆå¯é€‰ï¼‰`PYTHONPATH=.`

ç‚¹ **Apply â†’ OK**ï¼Œç„¶å â–¶ï¸ è¿è¡Œã€‚

> è¿™ç­‰ä»·äºåœ¨ç»ˆç«¯æ‰§è¡Œï¼š
>  `python -m flask run --host=0.0.0.0 --port=5001 --debug`

+ api ä½œä¸ºå•ç‹¬é¡¹ç›®æ‰“å¼€

# docker éƒ¨ç½²

## web - Build Docker Image from Source Code

https://docs.dify.ai/en/getting-started/install-self-hosted/start-the-frontend-docker-container

### Dockerfile

```
# base image
FROM node:22-alpine3.21 AS base
LABEL maintainer="takatost@gmail.com"

ARG HTTP_PROXY
ARG HTTPS_PROXY
ARG http_proxy
ARG https_proxy
ARG NPM_REGISTRY

ENV HTTP_PROXY=${HTTP_PROXY}
ENV HTTPS_PROXY=${HTTPS_PROXY}
ENV http_proxy=${http_proxy}
ENV https_proxy=${https_proxy}
ENV NPM_CONFIG_REGISTRY=${NPM_REGISTRY}

ENV HOSTNAME=0.0.0.0


# if you located in China, you can use aliyun mirror to speed up
RUN sed -i 's/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g' /etc/apk/repositories

# if you located in China, you can use taobao registry to speed up
RUN npm config set registry https://registry.npmmirror.com

RUN apk add --no-cache tzdata
RUN corepack enable
ENV PNPM_HOME="/pnpm"
ENV PATH="$PNPM_HOME:$PATH"
ENV NEXT_PUBLIC_BASE_PATH=


# install packages
FROM base AS packages

WORKDIR /app/web

COPY package.json .
COPY pnpm-lock.yaml .

# Use packageManager from package.json
RUN corepack install

RUN pnpm install --frozen-lockfile

# build resources
FROM base AS builder
WORKDIR /app/web
COPY --from=packages /app/web/ .
COPY . .

ENV NODE_OPTIONS="--max-old-space-size=4096"
RUN pnpm build:docker


# production stage
FROM base AS production

ENV NODE_ENV=production
ENV EDITION=SELF_HOSTED
ENV DEPLOY_ENV=PRODUCTION
ENV CONSOLE_API_URL=http://127.0.0.1:5001
ENV APP_API_URL=http://127.0.0.1:5001
ENV MARKETPLACE_API_URL=https://marketplace.dify.ai
ENV MARKETPLACE_URL=https://marketplace.dify.ai
ENV PORT=3000
ENV NEXT_TELEMETRY_DISABLED=1
ENV PM2_INSTANCES=2

# set timezone
ENV TZ=UTC
RUN ln -s /usr/share/zoneinfo/${TZ} /etc/localtime \
    && echo ${TZ} > /etc/timezone


WORKDIR /app/web
COPY --from=builder /app/web/public ./public
COPY --from=builder /app/web/.next/standalone ./
COPY --from=builder /app/web/.next/static ./.next/static

COPY docker/entrypoint.sh ./entrypoint.sh


# global runtime packages
RUN pnpm add -g pm2 \
    && mkdir /.pm2 \
    && chown -R 1001:0 /.pm2 /app/web \
    && chmod -R g=u /.pm2 /app/web

ARG COMMIT_SHA
ENV COMMIT_SHA=${COMMIT_SHA}

USER 1001
EXPOSE 3000
ENTRYPOINT ["/bin/sh", "./entrypoint.sh"]

```

### shell

```
#!/bin/sh
set -e

############################################
# åŸºæœ¬é…ç½®
############################################
IMAGE_NAME="dify-web"
CONTAINER_NAME="dify-web"
DOCKERFILE_DIR="."           # Dockerfile æ‰€åœ¨ç›®å½•
PORT="3000"
COMMIT_SHA=$(git rev-parse HEAD 2>/dev/null || echo "local")

############################################
# ä»£ç† & å›½å†…æºé…ç½®
############################################
ENABLE_PROXY=true

# !!! æ³¨æ„ï¼šå®¹å™¨å†…çš„ 127.0.0.1 æ˜¯â€œå®¹å™¨è‡ªå·±â€
# å¦‚æœä½ çš„ä»£ç†è·‘åœ¨å®¿ä¸»æœºä¸Šï¼ŒLinux ä¸‹å¸¸ç”¨ 172.17.0.1 æˆ– host.docker.internal
# ä½ ç°åœ¨æŒ‡å®š 127.0.0.1:7897ï¼Œæˆ‘æŒ‰ä½ è¦æ±‚å…ˆå†™æ­»ï¼Œä½ éœ€è¦çš„è¯å¯ä»¥è‡ªå·±æ”¹ PROXY_HOST
PROXY_HOST="127.0.0.1"
PROXY_PORT="7897"
PROXY_URL="http://${PROXY_HOST}:${PROXY_PORT}"

# npm / pnpm å›½å†…æº
NPM_REGISTRY="https://registry.npmmirror.com"

echo ">>> IMAGE_NAME     = ${IMAGE_NAME}"
echo ">>> CONTAINER_NAME = ${CONTAINER_NAME}"
echo ">>> DOCKERFILE_DIR = ${DOCKERFILE_DIR}"
echo ">>> PORT           = ${PORT}"
echo ">>> COMMIT_SHA     = ${COMMIT_SHA}"
echo ">>> ENABLE_PROXY   = ${ENABLE_PROXY}"
if [ "${ENABLE_PROXY}" = "true" ]; then
  echo ">>> PROXY_URL      = ${PROXY_URL}"
  echo ">>> NPM_REGISTRY   = ${NPM_REGISTRY}"
fi
echo

############################################
# åˆ é™¤æ—§å®¹å™¨
############################################
echo ">>> Removing old container if exists..."
if docker ps -a --format '{{.Names}}' | grep -w "${CONTAINER_NAME}" >/dev/null 2>&1; then
  docker stop "${CONTAINER_NAME}" >/dev/null 2>&1 || true
  docker rm   "${CONTAINER_NAME}" >/dev/null 2>&1 || true
  echo "--- Old container removed."
else
  echo "--- No container to remove."
fi
echo

############################################
# åˆ é™¤æ—§é•œåƒ
############################################
echo ">>> Removing old image if exists..."
if docker images --format '{{.Repository}}' | grep -w "${IMAGE_NAME}" >/dev/null 2>&1; then
  docker rmi -f "${IMAGE_NAME}" >/dev/null 2>&1 || true
  echo "--- Old image removed."
else
  echo "--- No image to remove."
fi
echo

############################################
# æ„é€  build å‚æ•°ï¼ˆå¸¦ä»£ç† & å›½å†…æºï¼‰
############################################
BUILD_ARGS="-t ${IMAGE_NAME} --build-arg COMMIT_SHA=${COMMIT_SHA}"

if [ "${ENABLE_PROXY}" = "true" ]; then
  BUILD_ARGS="${BUILD_ARGS} \
    --build-arg HTTP_PROXY=${PROXY_URL} \
    --build-arg HTTPS_PROXY=${PROXY_URL} \
    --build-arg http_proxy=${PROXY_URL} \
    --build-arg https_proxy=${PROXY_URL} \
    --build-arg NPM_REGISTRY=${NPM_REGISTRY}"
fi

echo ">>> docker build å‚æ•°:"
echo "${BUILD_ARGS}"
echo

############################################
# æ„å»ºé•œåƒ
############################################
echo ">>> Building new image..."
eval docker build --network=host   ${BUILD_ARGS} "${DOCKERFILE_DIR}"
echo "--- Build completed."
echo

############################################
# è¿è¡Œæ—¶ä»£ç†ç¯å¢ƒå˜é‡
############################################
RUN_PROXY_ENV=""
if [ "${ENABLE_PROXY}" = "true" ]; then
  RUN_PROXY_ENV="${RUN_PROXY_ENV} -e HTTP_PROXY=${PROXY_URL}"
  RUN_PROXY_ENV="${RUN_PROXY_ENV} -e HTTPS_PROXY=${PROXY_URL}"
  RUN_PROXY_ENV="${RUN_PROXY_ENV} -e http_proxy=${PROXY_URL}"
  RUN_PROXY_ENV="${RUN_PROXY_ENV} -e https_proxy=${PROXY_URL}"
fi

############################################
# å¯åŠ¨å®¹å™¨
############################################
echo ">>> Running container (detach + restart always)..."

# ç”¨ eval å±•å¼€ RUN_PROXY_ENV é‡Œçš„å¤šä¸ª -e  ç™»å½•çŠ¶æ€å›ºå®šåˆ°æŒ‡å®šurl, 
eval docker run -d \
  --name "${CONTAINER_NAME}" \
  --restart=always \
  -p "${PORT}:3000" \
  --network=host  \
  -e CONSOLE_API_URL="http://172.16.69.222:5001" \ 
  -e APP_API_URL="http://172.16.69.222:5001" \
  --env-file .env.local \
  ${RUN_PROXY_ENV} \
  "${IMAGE_NAME}"

echo ">>> Container started."
echo "ğŸŒ Visit: http://172.16.69.222:${PORT}"

```

## api & worker

https://legacy-docs.dify.ai/zh-hans/learn-more/faq/install-faq?utm_source=chatgpt.com

### dockerfile

```
# base image
FROM python:3.12-slim-bookworm AS base

# ===== æ¥æ”¶å¤–éƒ¨ build-argï¼ˆä»£ç† + å›½å†…æºï¼‰ =====
ARG HTTP_PROXY
ARG HTTPS_PROXY
ARG http_proxy
ARG https_proxy
ARG UV_INDEX_URL       # uv çš„å›½å†…æº
ARG PIP_INDEX_URL      # pip çš„å›½å†…æºï¼ˆå¤‡ç”¨ï¼‰

# ===== ç¯å¢ƒå˜é‡ï¼šè®© apt / uv / pip éƒ½èµ°ä»£ç† & å›½å†…æº =====
ENV HTTP_PROXY=${HTTP_PROXY}
ENV HTTPS_PROXY=${HTTPS_PROXY}
ENV http_proxy=${http_proxy}
ENV https_proxy=${https_proxy}

# uv ä½¿ç”¨å›½å†…æºï¼ˆç­‰ä»·äº --index-urlï¼‰
ENV UV_INDEX_URL=${UV_INDEX_URL}
# pip å¦‚æœåé¢ç”¨åˆ°ï¼Œä¹Ÿä¼šç”¨å›½å†…æº
ENV PIP_INDEX_URL=${PIP_INDEX_URL}


WORKDIR /app/api

# Install uv

RUN pip install --no-cache-dir uv


FROM base AS packages

# if you located in China, you can use aliyun mirror to speed up
RUN sed -i 's@deb.debian.org@mirrors.aliyun.com@g' /etc/apt/sources.list.d/debian.sources

RUN apt-get update \
    && apt-get install -y --no-install-recommends \
          # basic environment
          g++ \
          # for building gmpy2
          libmpfr-dev libmpc-dev

# Install Python dependencies
COPY pyproject.toml uv.lock ./
RUN uv sync --locked --no-dev

# production stage
FROM base AS production

ENV FLASK_APP=app.py
ENV EDITION=SELF_HOSTED
ENV DEPLOY_ENV=PRODUCTION
ENV CONSOLE_API_URL=http://127.0.0.1:5001
ENV CONSOLE_WEB_URL=http://127.0.0.1:3000
ENV SERVICE_API_URL=http://127.0.0.1:5001
ENV APP_WEB_URL=http://127.0.0.1:3000

EXPOSE 5001

# set timezone
ENV TZ=UTC

# Set UTF-8 locale
ENV LANG=en_US.UTF-8
ENV LC_ALL=en_US.UTF-8
ENV PYTHONIOENCODING=utf-8

WORKDIR /app/api

RUN \
    apt-get update \
    # Install dependencies
    && apt-get install -y --no-install-recommends \
        # basic environment
        curl nodejs \
        # for gmpy2 \
        libgmp-dev libmpfr-dev libmpc-dev \
        # For Security
        expat libldap-2.5-0 perl libsqlite3-0 zlib1g \
        # install fonts to support the use of tools like pypdfium2
        fonts-noto-cjk \
        # install a package to improve the accuracy of guessing mime type and file extension
        media-types \
        # install libmagic to support the use of python-magic guess MIMETYPE
        libmagic1 \
    && apt-get autoremove -y \
    && rm -rf /var/lib/apt/lists/*

# Copy Python environment and packages
ENV VIRTUAL_ENV=/app/api/.venv
COPY --from=packages ${VIRTUAL_ENV} ${VIRTUAL_ENV}
ENV PATH="${VIRTUAL_ENV}/bin:${PATH}"

# Download nltk data
RUN python -c "import nltk; nltk.download('punkt'); nltk.download('averaged_perceptron_tagger')"

ENV TIKTOKEN_CACHE_DIR=/app/api/.tiktoken_cache

RUN python -c "import tiktoken; tiktoken.encoding_for_model('gpt2')"

# Copy source code
COPY . /app/api/

# Copy entrypoint
COPY docker/entrypoint.sh /entrypoint.sh
RUN chmod +x /entrypoint.sh

ARG COMMIT_SHA
ENV COMMIT_SHA=${COMMIT_SHA}

ENTRYPOINT ["/bin/bash", "/entrypoint.sh"]

```



âœ… **åœ¨ç”¨è¿™ä¸ª Dockerfile æ—¶ï¼Œ`docker run` é‡Œæ ¹æœ¬ä¸éœ€è¦å†™ `uv run ...`**
 çœŸæ­£å¯åŠ¨ Flask / Celery çš„é€»è¾‘éƒ½å·²ç»å†™åœ¨ `api/docker/entrypoint.sh` é‡Œäº†ï¼Œå®ƒä¼šæ ¹æ® `MODE` ç¯å¢ƒå˜é‡è‡ªåŠ¨å†³å®šè·‘ API è¿˜æ˜¯ Workerã€‚

ç°åœ¨çš„è®¾è®¡ï¼šä¸€ä¸ªé•œåƒï¼Œå¤šç§æ¨¡å¼

ä» `entrypoint.sh` å¯ä»¥çœ‹å‡ºï¼Œ**åŒä¸€ä¸ªé•œåƒ**æ”¯æŒ 3 ç§ MODEï¼š

- `MODE=api`  ğŸ‘‰ è·‘ Flask / Gunicornï¼ˆå¯¹å¤–æä¾› http æœåŠ¡ï¼‰
- `MODE=worker` ğŸ‘‰ è·‘ Celery worker
- `MODE=beat` ğŸ‘‰ è·‘ Celery beat å®šæ—¶ä»»åŠ¡

ä¹Ÿå°±æ˜¯è¯´ï¼š**é•œåƒæ˜¯ä¸€ä¸ª**ï¼Œåªæ˜¯é€šè¿‡ `MODE` å†³å®šå®¹å™¨é‡Œåˆ°åº•è·‘å•¥ã€‚

### sh

```
#!/bin/bash
set -e

############################################
# åŸºæœ¬é…ç½®
############################################
IMAGE_NAME="dify-api"          # é•œåƒå
API_CONTAINER="dify-api"       # API å®¹å™¨å
WORKER_CONTAINER="dify-worker" # Worker å®¹å™¨å
DOCKERFILE_DIR="./"         # Dockerfile æ‰€åœ¨ç›®å½•
API_PORT=5001                  # å¯¹å¤–æš´éœ² API ç«¯å£

# å–å½“å‰ git æäº¤ï¼Œæ‰¾ä¸åˆ°å°±ç”¨ "local"
############################################
# ä»£ç† & å›½å†…æºé…ç½®
############################################

# æ˜¯å¦å¯ç”¨ä»£ç†ï¼ˆtrue/falseï¼‰
ENABLE_PROXY=true

# ===== ä»£ç†åœ°å€ï¼Œæ ¹æ®ä½ çš„ç³»ç»Ÿä¿®æ”¹ =====
# Linux é€šå¸¸ç”¨ Docker ç½‘å…³ 172.17.0.1 æˆ–å®¿ä¸»æœºå±€åŸŸç½‘ IP
PROXY_HOST="127.0.0.1"
PROXY_PORT="7897"
PROXY_URL="http://${PROXY_HOST}:${PROXY_PORT}"

# ===== å›½å†… PyPI é•œåƒï¼ˆuv / pip ä½¿ç”¨ï¼‰=====
# ä»»é€‰å…¶ä¸€ï¼š
#PYPI_MIRROR="https://mirrors.aliyun.com/pypi/simple"
PYPI_MIRROR="https://pypi.tuna.tsinghua.edu.cn/simple"

############################################
# æ‰“å°é…ç½®
############################################
echo ">>> IMAGE_NAME      = ${IMAGE_NAME}"
echo ">>> API_CONTAINER   = ${API_CONTAINER}"
echo ">>> WORKER_CONTAINER= ${WORKER_CONTAINER}"
echo ">>> DOCKERFILE_DIR  = ${DOCKERFILE_DIR}"
echo ">>> API_PORT        = ${API_PORT}"
echo ">>> ENABLE_PROXY    = ${ENABLE_PROXY}"
if [ "${ENABLE_PROXY}" = "true" ]; then
  echo ">>> PROXY_URL       = ${PROXY_URL}"
  echo ">>> PYPI_MIRROR     = ${PYPI_MIRROR}"
fi
echo

############################################
# åˆ é™¤æ—§å®¹å™¨
############################################
remove_container() {
  local NAME="$1"
  echo ">>> æ£€æŸ¥æ—§å®¹å™¨: ${NAME}"
  if docker ps -a --format '{{.Names}}' | grep -w "$NAME" >/dev/null 2>&1; then
    echo "    åœæ­¢ ${NAME} ..."
    docker stop "$NAME" >/dev/null 2>&1 || true
    echo "    åˆ é™¤ ${NAME} ..."
    docker rm "$NAME" >/dev/null 2>&1 || true
  else
    echo "    æœªæ‰¾åˆ°æ—§å®¹å™¨ã€‚"
  fi
}

remove_container "${API_CONTAINER}"
remove_container "${WORKER_CONTAINER}"
echo

############################################
# åˆ é™¤æ—§é•œåƒ
############################################
echo ">>> æ£€æŸ¥æ—§é•œåƒ: ${IMAGE_NAME}"
if docker images --format '{{.Repository}}' | grep -w "${IMAGE_NAME}" >/dev/null 2>&1; then
  echo "    åˆ é™¤æ—§é•œåƒ ..."
  docker rmi -f "${IMAGE_NAME}" >/dev/null 2>&1 || true
else
  echo "    æœªæ‰¾åˆ°æ—§é•œåƒã€‚"
fi
echo

############################################
# æ„é€  build å‚æ•°ï¼ˆåŒ…å«ä»£ç† & å›½å†…æºï¼‰
############################################
BUILD_ARGS="-t ${IMAGE_NAME}"

if [ "${ENABLE_PROXY}" = "true" ]; then
    BUILD_ARGS="$BUILD_ARGS \
      --build-arg HTTP_PROXY=${PROXY_URL} \
      --build-arg HTTPS_PROXY=${PROXY_URL} \
      --build-arg http_proxy=${PROXY_URL} \
      --build-arg https_proxy=${PROXY_URL} \
      --build-arg UV_INDEX_URL=${PYPI_MIRROR} \
      --build-arg PIP_INDEX_URL=${PYPI_MIRROR}"
fi

############################################
# æ„é€  run æ—¶çš„ä»£ç†ç¯å¢ƒå˜é‡
############################################
RUN_PROXY_ENV=""

if [ "${ENABLE_PROXY}" = "true" ]; then
    RUN_PROXY_ENV="$RUN_PROXY_ENV -e HTTP_PROXY=${PROXY_URL}"
    RUN_PROXY_ENV="$RUN_PROXY_ENV -e HTTPS_PROXY=${PROXY_URL}"
    RUN_PROXY_ENV="$RUN_PROXY_ENV -e http_proxy=${PROXY_URL}"
    RUN_PROXY_ENV="$RUN_PROXY_ENV -e https_proxy=${PROXY_URL}"
fi


############################################
# æ„å»ºé•œåƒ
############################################
echo ">>> å¼€å§‹æ„å»ºé•œåƒï¼ˆå¸¦ä»£ç† & å›½å†…æºï¼‰..."
eval docker build --network=host  $BUILD_ARGS "$DOCKERFILE_DIR"

echo ">>> é•œåƒæ„å»ºå®Œæˆ: ${IMAGE_NAME}_"

############################################
# å¯åŠ¨ API å®¹å™¨ (MODE=api)
############################################
echo ">>> å¯åŠ¨ API å®¹å™¨: ${API_CONTAINER}"

API_RUN_CMD="docker run -d \
  --name ${API_CONTAINER} \
  --restart=always \
  --network=host \
  -e MODE=api \
  -e EDITION=SELF_HOSTED \
  -e DEPLOY_ENV=PRODUCTION \
  --env-file .env \
  -v "$(pwd)/storage:/data/storage"
  ${RUN_PROXY_ENV} \
  ${IMAGE_NAME}"
eval ${API_RUN_CMD}

echo ">>> API å·²å¯åŠ¨: http://127.0.0.1:${API_PORT}"
echo

echo ">>> å¯åŠ¨ Worker å®¹å™¨: ${WORKER_CONTAINER}"

WORKER_RUN_CMD="docker run -d \
  --name ${WORKER_CONTAINER} \
  --restart=always \
  --network=host \
  -e MODE=worker \
  -e EDITION=SELF_HOSTED \
  -e DEPLOY_ENV=PRODUCTION \
  ${RUN_PROXY_ENV} \
  ${IMAGE_NAME}"
eval ${WORKER_RUN_CMD}

echo ">>> Worker å·²å¯åŠ¨ã€‚"
```

### ç›¸å…³é—®é¢˜

#### web éƒ¨ç½²æ­£å¸¸,  localhost:3000ä¸èƒ½è®¿é—®?

+ `docker logs -f dify-web`

  ```
  Starting server on hsiong-Z790-AORUS-PRO-X:3000
  - Local:   http://hsiong-Z790-AORUS-PRO-X:3000
  ```

+ ä¿®æ”¹ Dockerfile

  ```
  ENV HOSTNAME=0.0.0.0
  ```

#### ç™»å½•é—ªé€€

+ localhost: 3000 æˆ– 127.0.0.1:3000 åªæœ‰ä¸€ä¸ªèƒ½æ­£å¸¸ç™»å½•

ç›´æ¥åˆ æ‰ Dockerfile é‡Œçš„é‚£å‡ è¡Œ ENV

å¦‚æœä½ æ„¿æ„æ”¹é•œåƒæ„å»ºé€»è¾‘ï¼Œä¹Ÿå¯ä»¥åœ¨ `api` çš„ Dockerfile é‡ŒæŠŠè¿™å‡ è¡Œåˆ æ‰ï¼š

```
ENV CONSOLE_API_URL=http://127.0.0.1:5001
ENV CONSOLE_WEB_URL=http://127.0.0.1:3000
ENV SERVICE_API_URL=http://127.0.0.1:5001
ENV APP_WEB_URL=http://127.0.0.1:3000
ENV APP_API_URL=http://127.0.0.1:5001
```

è®©æ‰€æœ‰è¿™äº› URL å…¨éƒ¨**åªä» `.env`** æ¥æ§åˆ¶ã€‚

#### worker å¯åŠ¨å¤±è´¥

+ docker logs -f dify-worker

```
File "/app/api/extensions/storage/opendal_storage.py", line 39, in __init__ self.op = Operator(scheme=scheme, **kwargs).layer(retry_layer) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ opendal.exceptions.ConfigInvalid: ConfigInvalid (permanent) at => root is not specified ï¼› #!/bin/bash set -e
```

+ docker run åŠ ä¸Š

```
  --env-file .env \
  -v "$(pwd)/storage:/data/storage"
```

#### worker: ValueError: Port could not be cast to integer value as '${REDIS_PORT}

+ docker logs -f dify-worker

```
File "/app/api/.venv/lib/python3.12/site-packages/kombu/utils/url.py", line 72, in url_to_parts parts.port, ^^^^^^^^^^ File "/usr/local/lib/python3.12/urllib/parse.py", line 182, in port raise ValueError(f"Port could not be cast to integer value as {port!r}") ValueError: Port could not be cast to integer value as '${REDIS_PORT}'
```

+ sh 

```
cp .env .env.prod
sed -i "s/\${REDIS_PORT}/${REDIS_PORT}/g" .env.prod

docker run -> -e .env.prod
```

#### PrivkeyNotFoundError

+ docker logs -f dify-api

```
get_decrypt_decoding raise PrivkeyNotFoundError(f"Private key not found, tenant_id: {tenant_id}") libs.rsa.PrivkeyNotFoundError: Private key not found,
```

How to fix the â€œFile not foundâ€ error in local deployment logs?

```
ERROR:root:Unknown Error in completion
Traceback (most recent call last):
  File "/www/wwwroot/dify/dify/api/libs/rsa.py", line 45, in decrypt
    private_key = storage.load(filepath)
  File "/www/wwwroot/dify/dify/api/extensions/ext_storage.py", line 65, in load
    raise FileNotFoundError("File not found")
FileNotFoundError: File not found
```

This error might be due to changing the deployment method or deleting the `api/storage/privkeys` directory. This file is used to encrypt the large model keys, so its loss is irreversible. You can reset the encryption key pair with the following commands:

- Docker Compose deployment

  ```
  docker exec -it docker-api-1 flask reset-encrypt-key-pair
  ```

- Source code startupNavigate to the `api` directory

  ```
  flask reset-encrypt-key-pair
  ```

  Follow the prompts to reset.

#### dify Client error '404 Not Found' for url 'http://127.0.0.1:5002/plugin

+ dify plugin ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬

```
  # plugin daemon
  plugin_daemon:
    security_opt:
      - seccomp:unconfined
    privileged: true
    image: langgenius/dify-plugin-daemon:main-local-linux-amd64
```

#### Bad Request 400: Incorrect decryption

+ rsa åŠ å¯†å¼‚å¸¸,  ä»æ•°æ®åº“ä¸­åˆ é™¤ secret-key
+ apps -> æ ¹æ® name æ‰¾åˆ°  app_id
+ workflows -> app_id æ‰¾åˆ°æœ€æ–°çš„ workflowid,  å°†`environment_variables` ä¸­åˆ é™¤

#### xxx app is disabled

app -> ç¼–è¾‘ä¿¡æ¯ -> Backend Service API 

#### æ›´æ¢ api æ–‡æ¡£çš„åœ°å€

> api -> .env

+ api è°ƒç”¨åœ°å€

```
#Service API base URL

SERVICE_API_URL=http://127.0.0.1:5001
```

+ app run åœ°å€

```
# Web APP base URL
APP_WEB_URL=http://172.16.69.222:3000
```



# å¸¸ç”¨ç»„ä»¶

## Code

+ code è§£æé•¿æ–‡è¦ä½¿ç”¨ json.dumps(xxx), å¦åˆ™ä¼šå¯¼è‡´å¼‚å¸¸

## Variable Aggregator

+ å¤šå˜é‡æ··åˆ, ç”¨äºå¤šæµç¨‹åˆå¹¶ä¸€ä¸ªå€¼

+ æ”¯æŒå¤šç§Ÿå­—æ®µåˆå¹¶

+ æ”¯æŒç›´æ¥é€‰å–è¾“å‡ºå€¼, æ³¨æ„ç‚¹å¤–ä¾§çš„å€¼ä½œä¸ºå…¥å£å¯èƒ½æ˜¯ `object`

+ ä¸é€‚ç”¨äº if-else åˆ†æ”¯, ä¼šæœ‰å¼‚å¸¸; åªé€‚ç”¨äº fail branch

## Variable Assignerï¿¼  & Conversation Variables

è¿™ä¸¤ä¸ªç»„ä»¶å¿…é¡»ä¸€èµ·æ‰èƒ½ä½¿ç”¨, åªèƒ½ç”¨äº `chatflow`

+ ç”¨äºå®ç°å¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡

> workflow æ–°å¢å˜é‡æ— éœ€ Variable Assigner
>
> ç”¨ code ç»„ä»¶å³å¯

## User input

Dify çš„å·¥ä½œæµæ”¯æŒåœ¨æµç¨‹ä¸­æš‚åœï¼Œå¹¶å‘ç”¨æˆ·è¯·æ±‚è¾“å…¥ã€‚å½“ä½ éœ€è¦è®©ç”¨æˆ·é€‰æ‹©æŸä¸ªé€‰é¡¹æ—¶ï¼Œ

åªéœ€ï¼š`æ·»åŠ  User Input èŠ‚ç‚¹`

# ç›¸å…³é—®é¢˜

## è£…ä¸ä¸Šplugin

+ TONGYIinit environment for plugin langgenius/tongyi:0.1.0 failed too many times, you should consider the package is corrupted or your network is unstable

  pip æ²¡èµ°å›½å†…æº

+ ./middleware.env ä¿®æ”¹å€¼ä¸ç”Ÿæ•ˆ

å› ä¸º environment ä¼˜å…ˆçº§ å¤§äº env_file: - ./middleware.env

ä½ **ç¡®å®æœ‰å†™ `middleware.env`**ï¼Œä½†å®ƒâ€œä¸ç”Ÿæ•ˆâ€çš„åŸå› æ˜¯è¿™è¡ŒæŠŠå®ƒè¦†ç›–æ‰äº†ï¼š

```
environment:
  PIP_MIRROR_URL: ${PIP_MIRROR_URL:-}
```

è¦ç‚¹ä¸¤æ¡ï¼ˆå¾ˆå®¹æ˜“å¿½ç•¥ï¼‰ï¼š

1. **å˜é‡æ’å€¼ï¼ˆ${â€¦}ï¼‰åªè¯»å–å®¿ä¸»æœºç¯å¢ƒå˜é‡å’Œé¡¹ç›®æ ¹ç›®å½•çš„ `.env`**ï¼Œ**ä¸è¯»å–** `env_file`ï¼ˆå¦‚ `middleware.env`ï¼‰ã€‚
2. **åŒåé”®ä»¥ `environment:` ä¸ºå‡†è¦†ç›– `env_file:`**ã€‚ä½ è¿™è¡ŒæŠŠå€¼è§£ææˆç©ºå­—ç¬¦ä¸²ï¼ˆå› ä¸ºå®¿ä¸»æœº/`.env` æ²¡è¿™ä¸ªå˜é‡ï¼‰ï¼Œä»è€Œè¦†ç›–äº† `middleware.env` é‡Œçš„å€¼ã€‚

æ‰€ä»¥çœ‹èµ·æ¥å°±åƒâ€œæ²¡è¯»åˆ° `middleware.env`â€ã€‚

## workflow - batch run app å¹¶å‘æ•°

`GROUP_SIZE`

- app/components/share/text-generation/index.tsx:45 æŠŠ GROUP_SIZE å¸¸é‡å†™æ­»ä¸º 5ï¼Œå¹¶å¤‡æ³¨ â€œto avoid RPM limitâ€ã€‚æ‰€æœ‰æ‰¹é‡æ‰§è¡Œçš„é€»è¾‘éƒ½ä¼šç”¨   è¿™ä¸ªå¸¸é‡æ¥å†³å®šåŒä¸€æ—¶é—´èƒ½æœ‰å¤šå°‘ä»»åŠ¡å¤„åœ¨ running çŠ¶æ€ã€‚ 
- app/components/share/text-generation/index.tsx:282-323 çš„ handleRunBatch ä¼šä»ä¸Šä¼ çš„ CSV ç”Ÿæˆä»»åŠ¡åˆ—è¡¨ï¼šå‰ GROUP_SIZE æ¡ä»»åŠ¡è¢«æ ‡è®°ä¸º    runningï¼Œå…¶ä½™æ ‡è®°ä¸º pendingã€‚ç´§æ¥ç€è°ƒç”¨ setControlSend(Date.now())ï¼Œè¿™æ ·å½“å‰å¤„äº running çš„ä»»åŠ¡å¯¹åº”çš„ Result ç»„ä»¶éƒ½ä¼šæ”¶åˆ°åŒä¸€ä¸ª â€œå¼€å§‹      å‘é€â€ äº‹ä»¶ã€‚  
- app/components/share/text-generation/index.tsx:151-154 æŠŠ showTaskList é™åˆ¶ä¸º â€œé pendingâ€ çš„ä»»åŠ¡ï¼Œå› æ­¤åˆå§‹åªæ¸²æŸ“ 5 ä¸ª Result ç»„ä»¶ï¼›    é¢å¤–çš„ä»»åŠ¡è¦ç­‰çŠ¶æ€åˆ‡æˆ running æ‰ä¼šæ¸²æŸ“ï¼Œä»è€Œä¸ä¼šè§¦å‘æ›´å¤šå¹¶å‘è°ƒç”¨ã€‚ 
-  app/components/share/text-generation/index.tsx:324-357 çš„ handleCompleted åœ¨æŸä¸ªä»»åŠ¡ç»“æŸåç»Ÿè®¡å·²å®Œæˆæ•°é‡ã€‚å¦‚æœå®Œæˆæ•°é‡æ­£å¥½æ˜¯    GROUP_SIZE çš„å€æ•°ï¼Œæˆ–å‰©ä½™ä»»åŠ¡æ•°é‡ä¸è¶³ä¸€ä¸ªåˆ†ç»„ï¼Œåˆ™æŠŠä¸‹ä¸€æ‰¹ï¼ˆæœ€å¤š 5 æ¡ï¼‰pending ä»»åŠ¡åˆ‡æ¢æˆ runningï¼Œä»è€Œä»¥ 5 ä¸ªä¸ºä¸€ç»„æ¨è¿›ã€‚è¿™é‡Œä¹Ÿæ›´æ–°      batchCompletionRes ä»¥ä¾¿å¯¼å‡ºã€‚  
-  app/components/share/text-generation/result/index.tsx:413-437 æ¸²æŸ“æ—¶å°† controlSendã€taskId ç­‰å‚æ•°ä¼ ç»™ Resultã€‚Result å†…éƒ¨çš„    useEffectï¼ˆapp/components/share/text-generation/result/index.tsx:415-421ï¼‰ç›‘å¬ controlSendï¼Œä¸€æ—¦å˜åŒ–å°±è°ƒç”¨ handleSendï¼Œå› æ­¤åªæœ‰å½“å‰æ¸²      æŸ“å‡ºæ¥çš„ running ä»»åŠ¡æ‰ä¼šçœŸæ­£å‘èµ·è¯·æ±‚ã€‚  
-  app/components/share/text-generation/result/index.tsx:221-411 çš„ handleSend å½“ isWorkflow=true æ—¶ä¼šè°ƒç”¨ sendWorkflowMessageï¼ŒæŠŠ SSE    äº‹ä»¶å›è°ƒï¼ˆèŠ‚ç‚¹å¼€å§‹/ç»“æŸã€å¾ªç¯ã€æ–‡æœ¬å—ç­‰ï¼‰ç»‘å®šåˆ°å…·ä½“ä»»åŠ¡ã€‚  
-  service/share.ts:95-147 å®šä¹‰çš„ sendWorkflowMessage é€šè¿‡ ssePost(getUrl('workflows/run', â€¦)) å‘ workflows/run å‘èµ·æµå¼è¯·æ±‚ã€‚ä¹Ÿå°±æ˜¯    è¯´ï¼Œæ¯ä¸ª running ä»»åŠ¡éƒ½ä¼šå¼€å¯ä¸€ä¸ª SSE è¿æ¥ï¼›å› ä¸ºä¸Šå±‚æœ€å¤šåªè®© 5 ä¸ªä»»åŠ¡åŒæ—¶å¤„äº runningï¼Œæœ€ç»ˆå°±å®ç°äº† â€œBatch run app æ¯æ¬¡åªå¹¶å‘ 5 ä¸ªæ¥å£      è°ƒç”¨â€ã€‚  å¦‚æœéœ€è¦ä¿®æ”¹å¹¶å‘æ•°ï¼Œåªè¦è°ƒæ•´ `GROUP_SIZE`ï¼Œå¹¶ç¡®ä¿ç›¸åº”çš„çŠ¶æ€æ¨è¿›é€»è¾‘ä»ç„¶æ­£ç¡®å³å¯ã€‚

## workflow timeout

`NEXT_PUBLIC_TEXT_GENERATION_TIMEOUT_MS`

- app/components/share/text-generation/result/index.tsx:210 èµ·ï¼Œç»„ä»¶åœ¨å‘é€è¯·æ±‚æ—¶å¯åŠ¨ä¸€ä¸ª sleep(TEXT_GENERATION_TIMEOUT_MS) çš„å®šæ—¶å™¨ï¼›è‹¥åœ¨æ­¤æ—¶é—´å†…æµç¨‹è¿˜æœªç»“æŸï¼Œå°±æŠŠ isTimeout ç½®ä¸º true å¹¶åœ¨å®Œæˆå›è°ƒé‡Œå¼¹å‡º â€œResults are not displayed due to timeoutâ€¦â€ çš„ warningã€‚  

- TEXT_GENERATION_TIMEOUT_MS å®šä¹‰åœ¨ config/index.ts:339ï¼Œé€šè¿‡ getNumberConfig è¯»å–ã€‚å®ƒä¼˜å…ˆå–ç¯å¢ƒå˜é‡    NEXT_PUBLIC_TEXT_GENERATION_TIMEOUT_MSï¼Œå…¶æ¬¡å–åç«¯æš´éœ²çš„é…ç½®é¡¹ data-public-text-generation-timeout-msï¼ˆå‚è§ types/feature.ts:113 çš„    DatasetAttr.DATA_PUBLIC_TEXT_GENERATION_TIMEOUT_MSï¼‰ï¼Œè‹¥éƒ½ç¼ºå¤±åˆ™å›é€€åˆ°é»˜è®¤å€¼ 60000 æ¯«ç§’ã€‚  
- å› æ­¤ï¼Œè¿™ä¸ª timeout å¯ä»¥åœ¨éƒ¨ç½²æ—¶é€šè¿‡è®¾ç½® `NEXT_PUBLIC_TEXT_GENERATION_TIMEOUT_MS`ï¼ˆæˆ–ç›¸åº”çš„ dataset å±æ€§ï¼‰æ¥æ§åˆ¶ï¼›ä¸è®¾ç½®æ—¶é»˜è®¤ 60 ç§’åå‰ç«¯åœæ­¢ç­‰å¾…å¹¶æ˜¾ç¤ºè¯¥æç¤ºã€‚
